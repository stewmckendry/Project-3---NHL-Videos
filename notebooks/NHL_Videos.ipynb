{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ace7124-35e7-4474-9c6f-513690ecc2e5",
   "metadata": {},
   "source": [
    "# **NHL Skating Video Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d59c2d-d75f-4876-948b-332a521e0ea9",
   "metadata": {},
   "source": [
    "## **1: Setup & Import** <a id=\"functions\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8c34b726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/liammckendry/Project3_NHL_Videos/venv310/bin/python\n"
     ]
    }
   ],
   "source": [
    "# verify the python version being used is from hockey_ai virtual environment\n",
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3003df20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # OS library for interacting with the operating system\n",
    "import psutil  # psutil library for system monitoring\n",
    "\n",
    "import numpy as np  # NumPy library for numerical operations\n",
    "import pandas as pd # Pandas library for data manipulation\n",
    "import math  # Math library for mathematical functions\n",
    "\n",
    "from pytube import YouTube  # PyTube library for downloading YouTube videos\n",
    "import yt_dlp  # yt-dlp library for downloading videos from various platforms\n",
    "import cv2  # OpenCV library for computer vision tasks\n",
    "import mediapipe as mp  # MediaPipe library for machine learning solutions\n",
    "\n",
    "import matplotlib.pyplot as plt  # Matplotlib library for data visualization\n",
    "import seaborn as sns  # Seaborn library for data visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d953ec9a-09f6-4bb8-97ec-ffd1ae1cdd8b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## **2: Functions** <a id=\"functions\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cdaab6",
   "metadata": {},
   "source": [
    "### **2.1 Utility Functions** <a id=\"utility\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a48aa039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NHL_Videos.ipynb: 315798 bytes\n",
      ".DS_Store: 6148 bytes\n"
     ]
    }
   ],
   "source": [
    "def print_list_of_files_by_size():\n",
    "    \"\"\"\n",
    "    Print the list of files in the current directory sorted by size in descending order\n",
    "    \"\"\"\n",
    "    files = []\n",
    "    for file in os.listdir():\n",
    "        files.append((file, os.path.getsize(file)))\n",
    "    files.sort(key=lambda x: x[1], reverse=True)\n",
    "    for file in files:\n",
    "        print(f\"{file[0]}: {file[1]} bytes\")\n",
    "\n",
    "print_list_of_files_by_size()  # Print the list of files in the current directory sorted by size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1417c1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory: 16384.00 MB\n",
      "Used memory: 5014.36 MB\n",
      "Available memory: 3033.27 MB\n",
      "Memory usage percentage: 81.50%\n",
      "CPU usage percentage: 11.60%\n",
      "Number of CPU cores: 10\n",
      "Number of threads: 10\n",
      "Number of logical CPUs: 10\n",
      "CPU frequency: 4.00 MHz\n"
     ]
    }
   ],
   "source": [
    "# Function to print the memory usage of the current environment\n",
    "def print_memory_usage():\n",
    "    memory_info = psutil.virtual_memory()\n",
    "    print(f\"Total memory: {memory_info.total / (1024 ** 2):.2f} MB\")\n",
    "    print(f\"Used memory: {memory_info.used / (1024 ** 2):.2f} MB\")\n",
    "    print(f\"Available memory: {memory_info.available / (1024 ** 2):.2f} MB\")\n",
    "    print(f\"Memory usage percentage: {memory_info.percent:.2f}%\")\n",
    "    print(f\"CPU usage percentage: {psutil.cpu_percent(interval=1):.2f}%\")\n",
    "    print(f\"Number of CPU cores: {psutil.cpu_count()}\")\n",
    "    print(f\"Number of threads: {psutil.cpu_count(logical=False)}\")\n",
    "    print(f\"Number of logical CPUs: {psutil.cpu_count(logical=True)}\")\n",
    "    print(f\"CPU frequency: {psutil.cpu_freq().current:.2f} MHz\")\n",
    "\n",
    "print_memory_usage()  # Print the memory usage of the current environment\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cf2b837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_variables():\n",
    "    \"\"\"\n",
    "    Print a detailed list of all variables in the current namespace.\n",
    "    \"\"\"\n",
    "    get_ipython().magic('whos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2aff0209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_variables(*args):\n",
    "    \"\"\"\n",
    "    Delete all variables or specific variables provided in arguments, and clear garbage.\n",
    "    \n",
    "    Parameters:\n",
    "    *args: List of variable names to delete. If no arguments are provided, all variables will be deleted.\n",
    "    \"\"\"\n",
    "    \n",
    "    ipython = get_ipython()\n",
    "    \n",
    "    if args:\n",
    "        for var in args:\n",
    "            if var in ipython.user_ns:\n",
    "                del ipython.user_ns[var]\n",
    "                print(f\"Deleted variable: {var}\")\n",
    "            else:\n",
    "                print(f\"Variable not found: {var}\")\n",
    "    else:\n",
    "        ipython.magic('reset -f')\n",
    "        print(\"Deleted all variables.\")\n",
    "    \n",
    "    gc.collect()\n",
    "    print(\"Garbage collection complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d8e9f993-fbae-45b5-9313-18a7757fabb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function get a list of functions defined in notebook\n",
    "def printFunctions():\n",
    "    functions_list = [name for name, obj in globals().items() if callable(obj) and obj.__module__ == '__main__']\n",
    "    print(\"📌 Functions Defined in Notebook:\")\n",
    "    print(\"\\n\".join(functions_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d12ec0f5-b8a4-4e42-b1da-5f403489bfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check dataset structure and print first 5 rows\n",
    "def checkDataset(df):\n",
    "    df.info()\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4f055cdf-6606-47df-8656-0fd04c5ec2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to print API response in a readable dictionary so we can investigate the structure\n",
    "def read_APIResponseStructure(url):\n",
    "    \n",
    "    # Fetch game data\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    pp = pprint.PrettyPrinter(depth=4)  # Limits deep nesting\n",
    "    pp.pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "72456a6e-e7e8-405d-8a0e-20c3b4313bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor DataFrame Memory Usage\n",
    "\n",
    "def show_memory_usage():\n",
    "    \"\"\"Displays memory usage of all DataFrames in global scope.\"\"\"\n",
    "    for var_name in list(globals()):\n",
    "        var_value = globals()[var_name]\n",
    "        if isinstance(var_value, (pd.DataFrame, pd.Series)):  # Check if it's a DataFrame\n",
    "            print(f\"{var_name}: {sys.getsizeof(var_value) / (1024 * 1024):.2f} MB\")\n",
    "\n",
    "show_memory_usage()  # Run this after loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "475c7b8c-93e8-4149-8141-65c9c29eceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete Large DataFrames When No Longer Needed\n",
    "\n",
    "def delete_dataframe(df):\n",
    "    del df\n",
    "    gc.collect()  # Force garbage collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3079b363-4558-4467-8dfc-aa600e0aa577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize DataFrame Column Types (from 64->32 float or int vars)\n",
    "\n",
    "def optimize_dataframe(df):\n",
    "    \"\"\"Reduce memory usage by downcasting numerical columns.\"\"\"\n",
    "    for col in df.select_dtypes(include=['float64']):\n",
    "        df[col] = df[col].astype('float32')\n",
    "    for col in df.select_dtypes(include=['int64']):\n",
    "        df[col] = df[col].astype('int32')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e685ebc8-d6cf-410c-8a91-f2188cddf9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove hidden variables that are taking up memory\n",
    "\n",
    "def remove_hidden_variables():\n",
    "    %reset out -f\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77791453",
   "metadata": {},
   "source": [
    "### **2.2 Video Functions** <a id=\"video\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bf84894b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video 1/2: https://www.youtube.com/watch?v=y0wIRVQDbJc\n",
      "Skipping download, video already exists: ../data/video_1.mp4\n",
      "Video Length: 11.64 seconds, Total Frames: 349, FPS: 29.97002997002997\n",
      "Skipping frame extraction for video_1, frames already exist in: ../data/frames_1.  Number of frames: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741408432.536695 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408432.602365 1454657 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408432.616315 1454657 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping pose landmarks for video_1, pose output already exists in: ../data/pose_output_1. Number of pose estimates: 25\n",
      "frame time: 0.03336666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741408433.285903 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408433.292474 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408433.336650 1454684 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408433.342864 1454694 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408433.345949 1454684 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408433.352886 1454700 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408433.359908 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408433.411072 1454704 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408433.418801 1454704 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408433.429459 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408433.478106 1454714 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408433.486041 1454714 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408433.495775 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408433.545416 1454724 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408433.553284 1454724 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408433.560556 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408433.606833 1454734 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408433.613737 1454734 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408433.619830 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408433.664739 1454745 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408433.671291 1454745 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408433.678043 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408433.728213 1454754 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408433.736277 1454754 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408433.743316 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408433.792191 1454764 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408433.798429 1454764 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408433.805473 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408433.851510 1454775 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408433.859215 1454775 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408433.867584 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408433.918921 1454784 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408433.926326 1454784 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408433.934738 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408433.981887 1454794 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408433.988782 1454794 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408433.994956 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408434.040543 1454804 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408434.047742 1454804 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408434.054281 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408434.101106 1454815 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408434.107954 1454815 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408434.114652 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408434.162869 1454825 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408434.170357 1454825 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408434.177016 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408434.223157 1454836 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408434.230777 1454836 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408434.237418 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408434.284476 1454846 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408434.291611 1454846 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408434.298140 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408434.345829 1454856 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408434.353004 1454856 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408434.359769 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408434.407168 1454866 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408434.415426 1454866 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408434.422565 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408434.472755 1454877 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408434.481286 1454880 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408434.488695 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408434.539575 1454887 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408434.547431 1454887 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408434.554342 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408434.605130 1454905 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408434.613051 1454905 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408434.619708 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408434.666677 1454907 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408434.672836 1454907 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408434.679622 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408434.728205 1454917 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408434.736178 1454917 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408434.743552 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408434.791902 1454928 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408434.799551 1454928 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408434.806899 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408434.855752 1454938 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408434.862838 1454938 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408434.869520 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408434.917101 1454951 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408434.923994 1454951 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408434.931384 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408434.979401 1454961 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408434.987091 1454961 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408434.993459 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408435.042715 1454971 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408435.050870 1454971 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408435.058999 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408435.108917 1454989 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408435.116448 1454989 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408435.123067 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408435.169270 1454991 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408435.177229 1454991 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408435.184121 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408435.230927 1455009 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408435.237991 1455009 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408435.244489 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408435.294503 1455012 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408435.302198 1455012 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408435.309031 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408435.356382 1455022 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408435.363111 1455022 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408435.369420 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408435.416843 1455032 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408435.423721 1455032 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408435.430920 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408435.478362 1455042 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408435.485321 1455042 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408435.492416 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408435.539235 1455059 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408435.546515 1455059 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408435.553239 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408435.601952 1455067 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408435.609303 1455072 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408435.617405 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408435.663569 1455073 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408435.670762 1455077 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408435.676763 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408435.723602 1455083 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408435.730783 1455083 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408435.737290 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408435.784759 1455094 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408435.792680 1455094 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408435.800770 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408435.847657 1455104 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408435.854828 1455104 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408435.861366 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408435.906924 1455120 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408435.914509 1455120 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408435.920714 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408435.966015 1455125 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408435.973617 1455131 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408435.980361 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408436.028015 1455135 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408436.036429 1455135 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408436.043263 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408436.092230 1455160 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408436.099155 1455160 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408436.106430 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408436.152976 1455170 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408436.161125 1455170 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408436.167782 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408436.215849 1455180 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408436.223732 1455180 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408436.231111 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408436.277658 1455190 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408436.284944 1455190 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408436.292207 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408436.339554 1455200 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408436.347511 1455200 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408436.354479 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408436.403534 1455210 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408436.410910 1455210 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408436.425640 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408436.474629 1455232 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408436.483634 1455232 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing columns in function... Index(['frame', 'acceleration', 'velocity'], dtype='object')\n",
      "Metrics calculated for video 1/2\n",
      "Metrics combined for video 1/2.  Total metrics: 25\n",
      "Processing complete for video 1/2\n",
      "Processing video 2/2: https://www.youtube.com/watch?v=7jOCmk17dsc\n",
      "Skipping download, video already exists: ../data/video_2.mp4\n",
      "Video Length: 14.43 seconds, Total Frames: 346, FPS: 23.976023976023978\n",
      "Skipping frame extraction for video_2, frames already exist in: ../data/frames_2.  Number of frames: 35\n",
      "Skipping pose landmarks for video_2, pose output already exists in: ../data/pose_output_2. Number of pose estimates: 33\n",
      "frame time: 0.04170833333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1741408437.203461 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "I0000 00:00:1741408437.208742 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408437.253697 1455244 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408437.259193 1455253 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408437.266210 1455249 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408437.269235 1455256 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408437.277485 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408437.328483 1455264 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408437.337852 1455272 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408437.344773 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408437.394338 1455275 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408437.403149 1455280 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408437.410354 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408437.461282 1455284 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408437.469533 1455284 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408437.477212 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408437.529118 1455294 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408437.537791 1455294 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408437.545137 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408437.598429 1455308 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408437.606747 1455308 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408437.613741 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408437.662157 1455314 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408437.670573 1455314 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408437.677561 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408437.728944 1455324 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408437.737178 1455324 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408437.744350 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408437.791635 1455335 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408437.798761 1455335 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408437.805772 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408437.855442 1455344 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408437.861814 1455344 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408437.868762 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408437.917497 1455354 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408437.924969 1455354 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408437.934120 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408437.985869 1455364 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408437.994155 1455364 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408438.004926 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408438.056124 1455376 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408438.063592 1455376 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408438.069869 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408438.116163 1455386 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408438.123494 1455386 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408438.130802 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408438.180345 1455395 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408438.188045 1455395 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408438.194486 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408438.242242 1455405 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408438.249128 1455405 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408438.256031 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408438.303529 1455415 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408438.310843 1455415 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408438.317557 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408438.369265 1455425 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408438.376522 1455425 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408438.383987 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408438.433190 1455435 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408438.440104 1455435 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408438.446896 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408438.495457 1455445 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408438.502694 1455445 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408438.509566 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408438.556666 1455455 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408438.563974 1455455 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408438.569874 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408438.619061 1455469 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408438.626133 1455469 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408438.633868 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408438.684083 1455475 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408438.691276 1455481 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408438.697698 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408438.747209 1455486 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408438.754681 1455486 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408438.761147 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408438.811112 1455496 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408438.818222 1455496 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408438.825450 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408438.876458 1455506 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408438.884127 1455507 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408438.892163 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408438.939525 1455516 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408438.947004 1455516 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408438.953163 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408439.000239 1455527 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408439.007727 1455527 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408439.015020 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408439.063092 1455543 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408439.069658 1455543 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408439.076206 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408439.125568 1455552 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408439.133260 1455552 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408439.139863 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408439.187153 1455562 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408439.194343 1455562 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408439.201182 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408439.252335 1455572 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408439.260075 1455580 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408439.267629 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408439.316600 1455582 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408439.323183 1455590 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408439.330041 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408439.380287 1455592 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408439.387817 1455592 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408439.393992 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408439.441543 1455602 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408439.448349 1455602 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408439.455825 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408439.505348 1455612 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408439.512826 1455612 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408439.520487 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408439.570806 1455622 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408439.578621 1455622 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408439.585354 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408439.633139 1455632 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408439.640161 1455632 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408439.646585 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408439.695417 1455642 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408439.702522 1455646 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408439.709486 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408439.760196 1455652 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408439.767390 1455652 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408439.776539 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408439.825047 1455663 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408439.831748 1455663 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408439.838505 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408439.885687 1455673 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408439.893390 1455681 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408439.900426 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408439.952204 1455683 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408439.959537 1455690 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408439.968086 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408440.016780 1455700 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408440.024435 1455700 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408440.031350 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408440.080396 1455713 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408440.087528 1455713 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408440.093574 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408440.147103 1455723 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408440.154590 1455723 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408440.160617 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408440.208917 1455733 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408440.216196 1455733 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408440.223104 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408440.268984 1455744 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408440.275971 1455744 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408440.284091 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408440.331537 1455753 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408440.339140 1455753 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408440.345063 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408440.392673 1455764 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408440.400618 1455765 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408440.406965 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408440.454005 1455778 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408440.461525 1455777 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408440.468401 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408440.517159 1455791 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408440.523983 1455793 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408440.530827 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408440.578516 1455799 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408440.586275 1455799 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408440.592837 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408440.642698 1455808 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408440.650204 1455808 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408440.656951 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408440.705979 1455819 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408440.712770 1455819 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408440.719443 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408440.768465 1455828 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408440.776147 1455828 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408440.784589 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408440.832621 1455839 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408440.839370 1455839 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408440.846820 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408440.896325 1455848 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408440.902915 1455848 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408440.909446 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408440.956723 1455858 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408440.963617 1455858 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408440.969650 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408441.022187 1455868 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408441.029219 1455868 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408441.035137 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408441.085514 1455878 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408441.093230 1455878 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408441.100643 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408441.149373 1455908 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408441.156429 1455908 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408441.163267 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408441.210190 1455918 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408441.217719 1455918 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408441.225828 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408441.272761 1455929 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408441.279440 1455929 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408441.286277 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408441.334714 1455939 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408441.342586 1455939 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1741408441.350560 1354882 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4\n",
      "W0000 00:00:1741408441.400522 1455950 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741408441.408106 1455950 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing columns in function... Index(['frame', 'acceleration', 'velocity'], dtype='object')\n",
      "Metrics calculated for video 2/2\n",
      "Metrics combined for video 2/2.  Total metrics: 58\n",
      "Processing complete for video 2/2\n",
      "Metrics saved to ../data/metrics_output.csv\n",
      "Combined Metrics:\n",
      "           frame  acceleration  velocity\n",
      "0   frame_70.jpg      0.000000       0.0\n",
      "1  frame_200.jpg      0.000000       0.0\n",
      "2  frame_210.jpg   -167.183765       0.0\n",
      "3   frame_60.jpg    167.968712       0.0\n",
      "4  frame_300.jpg    -44.706934       0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def process_videos(url_list, output_dir, frame_interval, metrics, csv_output_path):\n",
    "    \"\"\"\n",
    "    Process a list of YouTube video URLs: download, extract frames, get pose landmarks, and calculate metrics.\n",
    "\n",
    "    Parameters:\n",
    "    url_list (list): List of YouTube video URLs.\n",
    "    output_dir (str): Directory to save downloaded videos and frames.\n",
    "    frame_interval (int): Interval of frames to save (e.g., save every k-th frame).\n",
    "    metrics (list): List of metrics to calculate.\n",
    "    csv_output_path (str): Path to save the calculated metrics CSV file.\n",
    "    \"\"\"\n",
    "    for i, youtube_url in enumerate(url_list):\n",
    "        try:\n",
    "            print(f\"Processing video {i+1}/{len(url_list)}: {youtube_url}\")\n",
    "\n",
    "            # Step 1: Download the video if it doesn't already exist\n",
    "            video_output_path = os.path.join(output_dir, f\"video_{i+1}.mp4\")\n",
    "            if not os.path.exists(video_output_path):\n",
    "                download_video(youtube_url, video_output_path)\n",
    "                print(f\"Video downloaded to: {video_output_path}\")\n",
    "            else:\n",
    "                print(f\"Skipping download, video already exists: {video_output_path}\")\n",
    "            \n",
    "            # Step 2: Retrieve and print video properties\n",
    "            duration, total_frames, fps = get_video_properties(video_output_path)\n",
    "            print(f\"Video Length: {duration:.2f} seconds, Total Frames: {total_frames}, FPS: {fps}\")\n",
    "            \n",
    "            # Step 3: Extract and save frames if the folder doesn't already exist\n",
    "            frame_folder_path = os.path.join(output_dir, f\"frames_{i+1}\")\n",
    "            if not os.path.exists(frame_folder_path) or not os.listdir(frame_folder_path):\n",
    "                extract_and_save_frames(video_output_path, frame_folder_path, frame_interval)\n",
    "                print(f\"Frames for video_{i+1} saved to: {frame_folder_path}. Number of frames: {len(os.listdir(frame_folder_path))}\")\n",
    "            else:\n",
    "                print(f\"Skipping frame extraction for video_{i+1}, frames already exist in: {frame_folder_path}.  Number of frames: {len(os.listdir(frame_folder_path))}\")\n",
    "            \n",
    "            # Step 4: Get and draw pose landmarks if the folder doesn't already exist\n",
    "            pose_folder_path = os.path.join(output_dir, f\"pose_output_{i+1}\")\n",
    "            pose_estimates = get_pose_landmarks(frame_folder_path)\n",
    "            if not os.path.exists(pose_folder_path) or not os.listdir(pose_folder_path):\n",
    "                draw_pose_landmarks(pose_estimates, frame_folder_path, pose_folder_path)\n",
    "                print(f\"Pose landmarks for video_{i+1} saved to: {pose_folder_path}.  Number of pose estimates: {len(pose_estimates)}\")\n",
    "            else:\n",
    "                print(f\"Skipping pose landmarks for video_{i+1}, pose output already exists in: {pose_folder_path}. Number of pose estimates: {len(pose_estimates)}\")\n",
    "\n",
    "            # Step 5: Calculate pose metrics and save to CSV\n",
    "            frame_time = 1 / fps\n",
    "            print(f\"frame time: {frame_time}\")\n",
    "            df_metrics = calculate_metrics(pose_estimates, frame_time, metrics)\n",
    "            print(f\"Metrics calculated for video {i+1}/{len(url_list)}\")\n",
    "            \n",
    "            # Step 6: Combine metrics from all videos\n",
    "            if i == 0:\n",
    "                df_combined = df_metrics\n",
    "            else:\n",
    "                df_combined = pd.concat([df_combined, df_metrics], ignore_index=True)\n",
    "            print(f\"Metrics combined for video {i+1}/{len(url_list)}.  Total metrics: {len(df_combined)}\")\n",
    "\n",
    "            # Step 7: Print completion message\n",
    "            print(f\"Processing complete for video {i+1}/{len(url_list)}\")\n",
    "            \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing video {i+1}/{len(url_list)}: {e}\")\n",
    "\n",
    "    # Save the combined metrics to a CSV file\n",
    "    df_combined.to_csv(csv_output_path, index=False)\n",
    "    print(f\"Metrics saved to {csv_output_path}\")\n",
    "\n",
    "    # Display the first few rows of the combined metrics DataFrame\n",
    "    print(\"Combined Metrics:\")\n",
    "    print(df_combined.head())\n",
    "    \n",
    "    # Plot the metrics for visualization\n",
    "    plot_skating_metrics(df_combined, metrics)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "url_list = [\n",
    "    \"https://www.youtube.com/watch?v=y0wIRVQDbJc\",\n",
    "    \"https://www.youtube.com/watch?v=7jOCmk17dsc\",\n",
    "]\n",
    "output_dir = \"../data\"\n",
    "frame_interval = 10\n",
    "metrics = [\"velocity\", \"acceleration\"]  # corrected \"glive_efficiency\" to \"glide_efficiency\"\n",
    "csv_output_path = \"../data/metrics_output.csv\"\n",
    "process_videos(url_list, output_dir, frame_interval, metrics, csv_output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "46240559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_video(youtube_url, output_path):\n",
    "    \"\"\"\n",
    "    Download a video from YouTube using yt-dlp.\n",
    "\n",
    "    Parameters:\n",
    "    youtube_url (str): URL of the YouTube video to download.\n",
    "    output_path (str): Path to save the downloaded video.\n",
    "    \"\"\"\n",
    "    # Define options for yt-dlp\n",
    "    ydl_opts = {\n",
    "        \"format\": \"bestvideo+bestaudio/best\",  # Download the best video and audio quality available\n",
    "        \"merge_output_format\": \"mp4\",  # Ensure video and audio are merged into an MP4 file\n",
    "        \"outtmpl\": output_path,  # Set the output file path\n",
    "        \"ffmpeg_location\": \"/opt/homebrew/bin/ffmpeg\"  # Specify the location of the ffmpeg executable\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Create a YoutubeDL object with the specified options\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            # Download the video from the provided URL\n",
    "            ydl.download([youtube_url])\n",
    "        print(\"Video downloaded successfully!\")\n",
    "    except Exception as e:\n",
    "        # Print an error message if an exception occurs\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ef8f9925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_properties(video_path):\n",
    "    \"\"\"\n",
    "    Get the video length, total number of frames, and frames per second (FPS).\n",
    "\n",
    "    Parameters:\n",
    "    video_path (str): Path to the video file.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing video length (float), total number of frames (int), and frames per second (float).\n",
    "    \"\"\"\n",
    "    # Open the video file using OpenCV (cv2) library\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)  # Frames per second\n",
    "    frame_count_total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # Total number of frames\n",
    "    duration = frame_count_total / fps  # Duration in seconds\n",
    "\n",
    "    return duration, frame_count_total, fps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "27fbe864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_save_frames(video_path, frame_folder_path, k):\n",
    "    \"\"\"\n",
    "    Extract and save every k-th frame from a video.\n",
    "\n",
    "    Parameters:\n",
    "    video_path (str): Path to the video file.\n",
    "    frame_folder_path (str): Path to the folder where frames will be saved.\n",
    "    k (int): Interval of frames to save (e.g., save every k-th frame).\n",
    "    \"\"\"\n",
    "    # Create folder for video frames if it doesn't exist\n",
    "    os.makedirs(frame_folder_path, exist_ok=True)\n",
    "\n",
    "    # Open the video file using OpenCV (cv2) library\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0  # Initialize frame count\n",
    "\n",
    "    while cap.isOpened():  # Loop until the video is opened\n",
    "        ret, frame = cap.read()  # Read a frame from the video\n",
    "        if not ret:  # If no frame is returned, break the loop\n",
    "            break\n",
    "\n",
    "        # Save every k-th frame\n",
    "        if frame_count % k == 0:  # Check if the frame count is a multiple of k\n",
    "            frame_filename = f\"{frame_folder_path}/frame_{frame_count}.jpg\"  # Create a filename for the frame\n",
    "            if not os.path.exists(frame_filename):  # Check if the frame file already exists\n",
    "                cv2.imwrite(frame_filename, frame)  # Save the frame as an image\n",
    "            else:\n",
    "                print(f\"Skipping {frame_filename}, already exists.\")\n",
    "\n",
    "        frame_count += 1  # Increment the frame count\n",
    "\n",
    "    cap.release()  # Release the video capture object\n",
    "    print(\"Frames extracted successfully!\")  # Print success message\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "af32d750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pose_landmarks(frame_folder_path):\n",
    "    \"\"\"\n",
    "    Return an array of pose landmarks for each frame.\n",
    "\n",
    "    Parameters:\n",
    "    frame_folder_path (str): Path to the folder containing video frames.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of tuples containing frame name and pose landmarks.\n",
    "    \"\"\"\n",
    "    # Initialize MediaPipe Pose solution\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)\n",
    "    \n",
    "    # Define valid image extensions\n",
    "    VALID_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp')\n",
    "\n",
    "    # List to store pose estimates\n",
    "    pose_estimates = []\n",
    "\n",
    "    # Iterate over each frame in the folder\n",
    "    for frame_name in os.listdir(frame_folder_path):\n",
    "        frame_path = os.path.join(frame_folder_path, frame_name)\n",
    "        \n",
    "        # Skip files that do not have valid image extensions\n",
    "        if not frame_name.lower().endswith(VALID_EXTENSIONS):\n",
    "            continue\n",
    "\n",
    "        # Read the frame image\n",
    "        frame = cv2.imread(frame_path)\n",
    "        if frame is None:\n",
    "            continue\n",
    "\n",
    "        # Convert the image from BGR to RGB\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Process the image to get pose landmarks\n",
    "        results = pose.process(rgb_frame)\n",
    "        \n",
    "        # If pose landmarks are detected, append them to the list\n",
    "        if results.pose_landmarks:\n",
    "            pose_estimates.append((frame_name, results.pose_landmarks))\n",
    "\n",
    "    return pose_estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5faab16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_pose_landmarks(pose_estimates, frame_folder_path, pose_folder_path):\n",
    "    \"\"\"\n",
    "    Create drawings of pose landmarks on each frame and store images in a new folder.\n",
    "\n",
    "    Parameters:\n",
    "    pose_estimates (list): A list of tuples containing frame name and pose landmarks.\n",
    "    frame_folder_path (str): Path to the folder containing video frames.\n",
    "    pose_folder_path (str): Path to the folder to save frames with pose landmarks.\n",
    "    \"\"\"\n",
    "    mp_drawing = mp.solutions.drawing_utils  # MediaPipe drawing utilities for drawing landmarks\n",
    "    os.makedirs(pose_folder_path, exist_ok=True)  # Create the output folder if it doesn't exist\n",
    "\n",
    "    for frame_name, pose_landmarks in pose_estimates:\n",
    "        frame_path = os.path.join(frame_folder_path, frame_name)  # Path to the original frame\n",
    "        output_path = os.path.join(pose_folder_path, frame_name.replace(\".jpg\", \"_landmark.jpg\"))  # Path to save the frame with landmarks\n",
    "        \n",
    "        if os.path.exists(output_path):  # Skip processing if the output file already exists\n",
    "            print(f\"Skipping {output_path}, already exists.\")\n",
    "            continue\n",
    "\n",
    "        frame = cv2.imread(frame_path)  # Read the frame image\n",
    "        if frame is None:  # Skip if the frame could not be read\n",
    "            continue\n",
    "\n",
    "        mp_drawing.draw_landmarks(frame, pose_landmarks, mp.solutions.pose.POSE_CONNECTIONS)  # Draw pose landmarks on the frame\n",
    "        cv2.imwrite(output_path, frame)  # Save the frame with landmarks to the output path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "26f8506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_frames_with_landmarks(pose_estimates):\n",
    "    \"\"\"\n",
    "    Return the number of frames with pose landmarks.\n",
    "\n",
    "    Parameters:\n",
    "    pose_estimates (list): A list of tuples containing frame name and pose landmarks.\n",
    "\n",
    "    Returns:\n",
    "    int: The number of frames with pose landmarks.\n",
    "    \"\"\"\n",
    "    return len(pose_estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3b33e604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The angle between points a, b, and c is 90.00 degrees.\n"
     ]
    }
   ],
   "source": [
    "# analyze skating metrics - measure knee bend angle\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    \"\"\"\n",
    "    Calculate angle between three points (a, b, c).\n",
    "    a, b, c are tuples of (x, y) coordinates.\n",
    "    \"\"\"\n",
    "    # Vector from point a to point b\n",
    "    ab = np.array([a[0] - b[0], a[1] - b[1]])\n",
    "    # Vector from point c to point b\n",
    "    bc = np.array([c[0] - b[0], c[1] - b[1]])\n",
    "\n",
    "    # Calculate the cosine of the angle using dot product and magnitudes of vectors\n",
    "    cosine_angle = np.dot(ab, bc) / (np.linalg.norm(ab) * np.linalg.norm(bc))\n",
    "    # Calculate the angle in degrees\n",
    "    angle = np.degrees(np.arccos(cosine_angle))\n",
    "    return angle\n",
    "\n",
    "# Example usage:\n",
    "# Define points a, b, and c as tuples of (x, y) coordinates\n",
    "a = (0.5, 0.5)\n",
    "b = (0.5, 0.6)\n",
    "c = (0.6, 0.6)\n",
    "\n",
    "# Calculate the angle between points a, b, and c\n",
    "angle = calculate_angle(a, b, c)\n",
    "print(f\"The angle between points a, b, and c is {angle:.2f} degrees.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "673e6401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_knee_angles(pose_estimates):\n",
    "    \"\"\"\n",
    "    Calculate knee angles for a set of frame pose estimates.\n",
    "\n",
    "    Parameters:\n",
    "    pose_estimates (list): A list of tuples containing frame name and pose landmarks.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of tuples containing frame name and knee angle.\n",
    "    \"\"\"\n",
    "    # Initialize MediaPipe Pose solution\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)\n",
    "    \n",
    "    knee_angles = []  # Initialize an empty list to store knee angles\n",
    "    for frame_name, pose_estimate in pose_estimates:  # Iterate over each frame and its pose estimate\n",
    "        # Extract landmarks for hip, knee, and ankle\n",
    "        landmarks = pose_estimate.landmark  # Get the landmarks from the pose estimate\n",
    "        hip = (landmarks[mp_pose.PoseLandmark.LEFT_HIP].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP].y)  # Get hip coordinates\n",
    "        knee = (landmarks[mp_pose.PoseLandmark.LEFT_KNEE].x, landmarks[mp_pose.PoseLandmark.LEFT_KNEE].y)  # Get knee coordinates\n",
    "        ankle = (landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].x, landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].y)  # Get ankle coordinates\n",
    "        \n",
    "        # Calculate knee bend angle\n",
    "        knee_angle = calculate_angle(hip, knee, ankle)  # Calculate the angle between hip, knee, and ankle\n",
    "        knee_angles.append((frame_name, knee_angle))  # Append the frame name and knee angle to the list\n",
    "    return knee_angles  # Return the list of knee angles\n",
    "\n",
    "    # Ensure proper cleanup\n",
    "    pose.close()\n",
    "    del pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0b862a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landmarks(pose_estimates, *landmark_names):\n",
    "    \"\"\"\n",
    "    Return specified landmarks for a set of frame pose estimates.\n",
    "\n",
    "    Parameters:\n",
    "    pose_estimates (list): A list of tuples containing frame name and pose landmarks.\n",
    "    *landmark_names (str): Names of landmarks to extract (e.g., 'left_hip', 'right_hip').\n",
    "\n",
    "    Returns:\n",
    "    list: A list of dictionaries containing frame name and specified landmarks.\n",
    "    \"\"\"\n",
    "    # Initialize MediaPipe Pose solution\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)\n",
    "    \n",
    "    # Define a dictionary to map landmark names to their corresponding indices in the pose landmarks\n",
    "    landmark_indices = {\n",
    "        'left_hip': mp_pose.PoseLandmark.LEFT_HIP,\n",
    "        'right_hip': mp_pose.PoseLandmark.RIGHT_HIP,\n",
    "        'left_knee': mp_pose.PoseLandmark.LEFT_KNEE,\n",
    "        'right_knee': mp_pose.PoseLandmark.RIGHT_KNEE,\n",
    "        'left_ankle': mp_pose.PoseLandmark.LEFT_ANKLE,\n",
    "        'right_ankle': mp_pose.PoseLandmark.RIGHT_ANKLE,\n",
    "        'left_shoulder': mp_pose.PoseLandmark.LEFT_SHOULDER,\n",
    "        'right_shoulder': mp_pose.PoseLandmark.RIGHT_SHOULDER,\n",
    "        'left_elbow': mp_pose.PoseLandmark.LEFT_ELBOW,\n",
    "        'right_elbow': mp_pose.PoseLandmark.RIGHT_ELBOW,\n",
    "        'left_wrist': mp_pose.PoseLandmark.LEFT_WRIST,\n",
    "        'right_wrist': mp_pose.PoseLandmark.RIGHT_WRIST,\n",
    "        'left_eye': mp_pose.PoseLandmark.LEFT_EYE,\n",
    "        'right_eye': mp_pose.PoseLandmark.RIGHT_EYE,\n",
    "        'nose': mp_pose.PoseLandmark.NOSE,\n",
    "        'left_ear': mp_pose.PoseLandmark.LEFT_EAR,\n",
    "        'right_ear': mp_pose.PoseLandmark.RIGHT_EAR,\n",
    "        'mouth_left': mp_pose.PoseLandmark.MOUTH_LEFT,\n",
    "        'mouth_right': mp_pose.PoseLandmark.MOUTH_RIGHT,\n",
    "        'left_pinky': mp_pose.PoseLandmark.LEFT_PINKY,\n",
    "        'right_pinky': mp_pose.PoseLandmark.RIGHT_PINKY,\n",
    "        'left_index': mp_pose.PoseLandmark.LEFT_INDEX,\n",
    "        'right_index': mp_pose.PoseLandmark.RIGHT_INDEX,\n",
    "        'left_thumb': mp_pose.PoseLandmark.LEFT_THUMB,\n",
    "        'right_thumb': mp_pose.PoseLandmark.RIGHT_THUMB,\n",
    "        'left_foot_index': mp_pose.PoseLandmark.LEFT_FOOT_INDEX,\n",
    "        'right_foot_index': mp_pose.PoseLandmark.RIGHT_FOOT_INDEX,\n",
    "        'left_heel': mp_pose.PoseLandmark.LEFT_HEEL,\n",
    "        'right_heel': mp_pose.PoseLandmark.RIGHT_HEEL,\n",
    "        'left_big_toe': mp_pose.PoseLandmark.LEFT_BIG_TOE,\n",
    "        'right_big_toe': mp_pose.PoseLandmark.RIGHT_BIG_TOE,\n",
    "        'left_small_toe': mp_pose.PoseLandmark.LEFT_SMALL_TOE,\n",
    "        'right_small_toe': mp_pose.PoseLandmark.RIGHT_SMALL_TOE\n",
    "    }\n",
    "    \n",
    "    results = []  # Initialize an empty list to store the results\n",
    "    for frame_name, pose_estimate in pose_estimates:  # Iterate over each frame and its pose estimate\n",
    "        landmarks = pose_estimate.landmark  # Get the landmarks from the pose estimate\n",
    "        frame_landmarks = {'frame_name': frame_name}  # Initialize a dictionary to store the frame name and landmarks\n",
    "        for name in landmark_names:  # Iterate over the specified landmark names\n",
    "            if name in landmark_indices:  # Check if the landmark name is in the dictionary\n",
    "                landmark = landmarks[landmark_indices[name]]  # Get the landmark using its index\n",
    "                frame_landmarks[name] = (landmark.x, landmark.y)  # Store the landmark coordinates in the dictionary\n",
    "        results.append(frame_landmarks)  # Append the dictionary to the results list\n",
    "    return results  # Return the list of dictionaries containing frame names and specified landmarks\n",
    "\n",
    "    # Ensure proper cleanup\n",
    "    pose.close()\n",
    "    del pose\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "67c1dbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for calculating Euclidean distance (stride length)\n",
    "def euclidean_distance(p1, p2):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean distance between two points.\n",
    "\n",
    "    Parameters:\n",
    "    p1 (tuple): The (x, y) coordinates of the first point.\n",
    "    p2 (tuple): The (x, y) coordinates of the second point.\n",
    "\n",
    "    Returns:\n",
    "    float: The Euclidean distance between the two points.\n",
    "    \"\"\"\n",
    "    # Calculate the difference in x-coordinates and y-coordinates\n",
    "    dx = p1[0] - p2[0]\n",
    "    dy = p1[1] - p2[1]\n",
    "    \n",
    "    # Calculate the Euclidean distance using the Pythagorean theorem\n",
    "    distance = (dx**2 + dy**2) ** 0.5\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c30d5569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate knee angle\n",
    "def calculate_knee_angle(landmarks):\n",
    "    \"\"\"\n",
    "    Calculate the knee angle based on the positions of the hip, knee, and ankle landmarks.\n",
    "\n",
    "    Parameters:\n",
    "    landmarks (google._upb._message.RepeatedCompositeContainer): Pose landmarks.\n",
    "\n",
    "    Returns:\n",
    "    float: The calculated knee angle in degrees.\n",
    "    \"\"\"\n",
    "    # Initialize MediaPipe Pose solution\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)\n",
    "    \n",
    "    # Extract x and y coordinates of the hip\n",
    "    hip = (landmarks[mp_pose.PoseLandmark.LEFT_HIP].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP].y)\n",
    "    \n",
    "    # Extract x and y coordinates of the knee\n",
    "    knee = (landmarks[mp_pose.PoseLandmark.LEFT_KNEE].x, landmarks[mp_pose.PoseLandmark.LEFT_KNEE].y)\n",
    "    \n",
    "    # Extract x and y coordinates of the ankle\n",
    "    ankle = (landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].x, landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].y)\n",
    "    \n",
    "    # Calculate the angle between the hip, knee, and ankle\n",
    "    angle = calculate_angle(hip, knee, ankle)\n",
    "\n",
    "    # Ensure proper cleanup\n",
    "    pose.close()\n",
    "    del pose\n",
    "    \n",
    "    return angle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2f23116f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate stride length\n",
    "def calculate_stride_length(landmarks):\n",
    "    \"\"\"\n",
    "    Calculate the stride length based on the positions of the left and right ankles.\n",
    "\n",
    "    Parameters:\n",
    "    landmarks (google._upb._message.RepeatedCompositeContainer): Pose landmarks.\n",
    "\n",
    "    Returns:\n",
    "    float: The calculated stride length.\n",
    "    \"\"\"\n",
    "    # Initialize MediaPipe Pose solution\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)\n",
    "    \n",
    "    # Extract x and y coordinates of the left ankle\n",
    "    left_foot = (landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].x, landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].y)\n",
    "    \n",
    "    # Extract x and y coordinates of the right ankle\n",
    "    right_foot = (landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE].x, landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE].y)\n",
    "    \n",
    "    # Calculate the Euclidean distance between the left and right ankle positions\n",
    "    stride_length = euclidean_distance(left_foot, right_foot)\n",
    "    \n",
    "    # Ensure proper cleanup\n",
    "    pose.close()\n",
    "    del pose\n",
    "    \n",
    "    return stride_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1af09112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate hip stability\n",
    "def calculate_hip_stability(landmarks):\n",
    "    \"\"\"\n",
    "    Calculate the stability of the hips based on the Euclidean distance between the left and right hip landmarks.\n",
    "\n",
    "    Parameters:\n",
    "    landmarks (google._upb._message.RepeatedCompositeContainer): Pose landmarks.\n",
    "\n",
    "    Returns:\n",
    "    float: The calculated hip stability.\n",
    "    \"\"\"\n",
    "    # Initialize MediaPipe Pose solution\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)\n",
    "    \n",
    "    # Extract x and y coordinates of the left hip\n",
    "    left_hip = (landmarks[mp_pose.PoseLandmark.LEFT_HIP].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP].y)\n",
    "    \n",
    "    # Extract x and y coordinates of the right hip\n",
    "    right_hip = (landmarks[mp_pose.PoseLandmark.RIGHT_HIP].x, landmarks[mp_pose.PoseLandmark.RIGHT_HIP].y)\n",
    "    \n",
    "    # Calculate the Euclidean distance between the left and right hip positions\n",
    "    hip_stability = euclidean_distance(left_hip, right_hip)\n",
    "    \n",
    "    # Ensure proper cleanup\n",
    "    pose.close()\n",
    "    del pose\n",
    "    \n",
    "    return hip_stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fcec3a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate forward lean angle\n",
    "def calculate_forward_lean(landmarks):\n",
    "    \"\"\"\n",
    "    Calculate the forward lean angle based on shoulder, torso, and knee landmarks.\n",
    "\n",
    "    Parameters:\n",
    "    landmarks (google._upb._message.RepeatedCompositeContainer): Pose landmarks.\n",
    "\n",
    "    Returns:\n",
    "    float: The calculated forward lean angle in degrees.\n",
    "    \"\"\"\n",
    "    # Initialize MediaPipe Pose solution\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)\n",
    "    \n",
    "    # Extract x and y coordinates of the left shoulder\n",
    "    shoulder = (landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y)\n",
    "    \n",
    "    # Extract x and y coordinates of the left hip (torso)\n",
    "    torso = (landmarks[mp_pose.PoseLandmark.LEFT_HIP].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP].y)\n",
    "    \n",
    "    # Extract x and y coordinates of the left knee\n",
    "    knee = (landmarks[mp_pose.PoseLandmark.LEFT_KNEE].x, landmarks[mp_pose.PoseLandmark.LEFT_KNEE].y)\n",
    "    \n",
    "    # Calculate the angle between the shoulder, torso, and knee\n",
    "    angle = calculate_angle(shoulder, torso, knee)\n",
    "    \n",
    "    # Ensure proper cleanup\n",
    "    pose.close()\n",
    "    del pose\n",
    "    \n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2c67780c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate stride cadence (steps per second)\n",
    "def calculate_stride_cadence(pose_estimates, frame_time):\n",
    "    \"\"\"\n",
    "    Calculate the stride cadence (steps per second) from pose estimates.\n",
    "\n",
    "    Parameters:\n",
    "    pose_estimates (list): List of tuples containing frame name and pose landmarks.\n",
    "    frame_time (float): Time duration of each frame.\n",
    "\n",
    "    Returns:\n",
    "    float: Stride cadence (steps per second).\n",
    "    \"\"\"\n",
    "    # Initialize MediaPipe Pose solution\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)\n",
    "    \n",
    "    left_step_count, right_step_count = 0, 0  # Initialize step counts for left and right foot\n",
    "    prev_left_foot, prev_right_foot = None, None  # Initialize previous positions of left and right foot\n",
    "\n",
    "    for frame_name, pose_estimate in pose_estimates:\n",
    "        landmarks = pose_estimate.landmark  # Extract landmarks from pose estimate\n",
    "        left_foot = (landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].x, landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].y)  # Get left foot position\n",
    "        right_foot = (landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE].x, landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE].y)  # Get right foot position\n",
    "\n",
    "        if prev_left_foot is not None and prev_right_foot is not None:\n",
    "            # Detect if a step has occurred for left and right foot\n",
    "            left_step, right_step, _, _ = detect_stride_cadence(landmarks, prev_left_foot, prev_right_foot, frame_time)\n",
    "            if left_step:\n",
    "                left_step_count += 1  # Increment left step count if a step is detected\n",
    "            if right_step:\n",
    "                right_step_count += 1  # Increment right step count if a step is detected\n",
    "\n",
    "        prev_left_foot, prev_right_foot = left_foot, right_foot  # Update previous foot positions\n",
    "\n",
    "    total_steps = left_step_count + right_step_count  # Calculate total steps\n",
    "\n",
    "    # Ensure proper cleanup\n",
    "    pose.close()\n",
    "    del pose\n",
    "    \n",
    "    return total_steps / (len(pose_estimates) * frame_time)  # Calculate and return stride cadence (steps per second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6c7dd011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate arm swing angle\n",
    "def calculate_arm_swing(landmarks):\n",
    "    \"\"\"\n",
    "    Calculate the arm swing angle based on shoulder and hip landmarks.\n",
    "\n",
    "    Parameters:\n",
    "    landmarks (google._upb._message.RepeatedCompositeContainer): Pose landmarks.\n",
    "\n",
    "    Returns:\n",
    "    float: The calculated arm swing angle in degrees.\n",
    "    \"\"\"\n",
    "    # Initialize MediaPipe Pose solution\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)\n",
    "    \n",
    "    # Extract x and y coordinates of the left shoulder\n",
    "    left_shoulder = (landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y)\n",
    "    \n",
    "    # Extract x and y coordinates of the right shoulder\n",
    "    right_shoulder = (landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].x, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].y)\n",
    "    \n",
    "    # Extract x and y coordinates of the left hip (torso)\n",
    "    torso = (landmarks[mp_pose.PoseLandmark.LEFT_HIP].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP].y)\n",
    "    \n",
    "    # Ensure proper cleanup\n",
    "    pose.close()\n",
    "    del pose\n",
    "\n",
    "    # Calculate the angle between the left shoulder, right shoulder, and torso\n",
    "    angle = calculate_angle(left_shoulder, right_shoulder, torso)\n",
    "    return angle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ffb1a007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get position (left_hip position as centre of mass)\n",
    "def get_position(landmarks):\n",
    "    \"\"\"\n",
    "    Get the position of the left hip from the pose landmarks.\n",
    "\n",
    "    Parameters:\n",
    "    landmarks (google._upb._message.RepeatedCompositeContainer): Pose landmarks.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Position of the left hip as (x, y) coordinates.\n",
    "\n",
    "    Raises:\n",
    "    ValueError: If the landmark positions are negative.\n",
    "    \"\"\"\n",
    "    # Initialize MediaPipe Pose solution\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)\n",
    "    \n",
    "    # Extract x and y coordinates of the left hip\n",
    "    left_hip_x = landmarks[mp_pose.PoseLandmark.LEFT_HIP].x\n",
    "    left_hip_y = landmarks[mp_pose.PoseLandmark.LEFT_HIP].y\n",
    "    \n",
    "    # Check if the coordinates are non-negative\n",
    "    if left_hip_x < 0 or left_hip_y < 0:\n",
    "        raise ValueError(\"Landmark positions must be non-negative\")\n",
    "    \n",
    "    # Ensure proper cleanup\n",
    "    pose.close()\n",
    "    del pose\n",
    "    \n",
    "    # Return the position as a tuple\n",
    "    return (left_hip_x, left_hip_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9f041151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute velocity (current position - previous position / frame time)\n",
    "def compute_velocity(current_position, prev_position, frame_time):\n",
    "    \"\"\"\n",
    "    Compute the velocity given the current and previous positions and the frame time.\n",
    "\n",
    "    Parameters:\n",
    "    current_position (tuple): Current position as a tuple (x, y).\n",
    "    prev_position (tuple): Previous position as a tuple (x, y).\n",
    "    frame_time (float): Time duration of each frame.\n",
    "\n",
    "    Returns:\n",
    "    float: Combined velocity.\n",
    "    \"\"\"\n",
    "    if frame_time == 0:\n",
    "        raise ValueError(\"Frame time must be greater than zero.\")  # Raise an error if frame time is zero to avoid division by zero\n",
    "\n",
    "    # Calculate velocity for each component (x and y)\n",
    "    vx = (current_position[0] - prev_position[0]) / frame_time\n",
    "    vy = (current_position[1] - prev_position[1]) / frame_time\n",
    "\n",
    "    # Calculate combined velocity using Euclidean distance formula\n",
    "    combined_velocity = (vx**2 + vy**2) ** 0.5\n",
    "\n",
    "    return combined_velocity  # Return the velocity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "72b7ad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute acceleration (current velocity - previous velocity / frame time)\n",
    "def compute_acceleration(current_velocity, prev_velocity, frame_time):\n",
    "    \"\"\"\n",
    "    Compute the acceleration given the current and previous velocities and the frame time.\n",
    "\n",
    "    Parameters:\n",
    "    current_velocity (float): Current velocity (float)\n",
    "    prev_velocity (float): Previous velocity (float)\n",
    "    frame_time (float): Time duration of each frame.\n",
    "\n",
    "    Returns:\n",
    "    float: Combined acceleration.\n",
    "    \"\"\"\n",
    "    if frame_time == 0:\n",
    "        raise ValueError(\"Frame time cannot be zero.\")  # Raise an error if frame time is zero to avoid division by zero\n",
    "\n",
    "    # Calculate acceleration\n",
    "    acceleration = (current_velocity - prev_velocity) / frame_time  # Dividing by frame time instead of previous velocity\n",
    "    \n",
    "    return acceleration  # Return the acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e0f698e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate specified metrics and append to data frame\n",
    "def calculate_metrics(pose_estimates, frame_time, metrics):\n",
    "    \"\"\"\n",
    "    Calculate specified metrics from pose estimates and append to a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        pose_estimates (list): List of tuples containing frame names and pose estimates.\n",
    "        frame_time (float): Time duration of each frame.\n",
    "        metrics (list): List of metrics to calculate.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the calculated metrics for each frame.\n",
    "    \"\"\"\n",
    "    # Initialize MediaPipe Pose solution\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)\n",
    "    \n",
    "    # Initialize lists to store metrics\n",
    "    frame_numbers, knee_angles, stride_lengths, hip_stabilities, lean_angles = [], [], [], [], []\n",
    "    stride_cadences, arm_swing_angles, glide_times, glide_ratios, glide_lengths, glide_symmetries, glide_stabilities, glide_efficiencies = [], [], [], [], [], [], [], []\n",
    "    positions, velocities, accelerations = [], [], []\n",
    "    prev_position, prev_velocity = None, None\n",
    "\n",
    "    # Iterate through each frame and its corresponding pose estimate\n",
    "    for frame_name, pose_estimate in pose_estimates:\n",
    "        landmarks = pose_estimate.landmark  # Extract landmarks from pose estimate\n",
    "\n",
    "        # Calculate knee angle if specified in metrics\n",
    "        if 'knee_angle' in metrics:\n",
    "            knee_angle = calculate_knee_angle(landmarks)\n",
    "            knee_angles.append(knee_angle)\n",
    "\n",
    "        # Calculate stride length if specified in metrics\n",
    "        if 'stride_length' in metrics:\n",
    "            stride_length = calculate_stride_length(landmarks)\n",
    "            stride_lengths.append(stride_length)\n",
    "        \n",
    "        # calculate stride cadence if specified in metrics\n",
    "        if 'stride_cadence' in metrics:\n",
    "            stride_cadence = calculate_stride_cadence(pose_estimates, frame_time)\n",
    "            stride_cadences.append(stride_cadence)\n",
    "\n",
    "        # Calculate hip stability if specified in metrics\n",
    "        if 'hip_stability' in metrics:\n",
    "            hip_stability = calculate_hip_stability(landmarks)\n",
    "            hip_stabilities.append(hip_stability)\n",
    "\n",
    "        # Calculate forward lean angle if specified in metrics\n",
    "        if 'lean_angle' in metrics:\n",
    "            lean_angle = calculate_forward_lean(landmarks)\n",
    "            lean_angles.append(lean_angle)\n",
    "        \n",
    "        # Calculate arm swing angle if specified in metrics\n",
    "        if 'arm_swing_angle' in metrics:\n",
    "            arm_swing_angle = calculate_arm_swing(landmarks)\n",
    "            arm_swing_angles.append(arm_swing_angle)\n",
    "\n",
    "        # Calculate acceleration if specified in metrics\n",
    "        if 'acceleration' in metrics: \n",
    "            current_position = get_position(landmarks)\n",
    "            if prev_position is None and prev_velocity is None: # first frame\n",
    "                current_velocity = None\n",
    "                acceleration = 0\n",
    "            elif prev_velocity is None: # second frame\n",
    "                current_velocity = compute_velocity(current_position, prev_position, frame_time)\n",
    "                acceleration = 0\n",
    "            else: # subsequent frames\n",
    "                current_velocity = compute_velocity(current_position, prev_position, frame_time)\n",
    "                acceleration = compute_acceleration(current_velocity, prev_velocity, frame_time)\n",
    "            accelerations.append(acceleration)\n",
    "            prev_position = current_position\n",
    "            prev_velocity = current_velocity\n",
    "\n",
    "        # Calculate velocity if specified in metrics\n",
    "        if 'velocity' in metrics: \n",
    "            current_position = get_position(landmarks)\n",
    "            if prev_position is None:\n",
    "                velocity = 0\n",
    "            else:\n",
    "                velocity = compute_velocity(current_position, prev_position, frame_time)\n",
    "            prev_position = current_position\n",
    "            velocities.append(velocity)\n",
    "\n",
    "        # Append frame name to frame numbers list\n",
    "        frame_numbers.append(frame_name)\n",
    "\n",
    "    # Create a dictionary to store the data\n",
    "    data = {\n",
    "        \"frame\": frame_numbers,\n",
    "        \"knee_angle\": knee_angles if knee_angles else None,\n",
    "        \"stride_length\": stride_lengths if stride_lengths else None,\n",
    "        \"hip_stability\": hip_stabilities if hip_stabilities else None,\n",
    "        \"lean_angle\": lean_angles if lean_angles else None,\n",
    "        \"stride_cadence\": stride_cadences if stride_cadences else None,\n",
    "        \"arm_swing_angle\": arm_swing_angles if arm_swing_angles else None,\n",
    "        \"glide_length\": glide_lengths if glide_lengths else None,\n",
    "        \"glide_symmetry\": glide_symmetries if glide_symmetries else None,\n",
    "        \"glide_stability\": glide_stabilities if glide_stabilities else None,\n",
    "        \"glide_efficiency\": glide_efficiencies if glide_efficiencies else None,\n",
    "        \"acceleration\": accelerations if accelerations else None,\n",
    "        \"velocity\": velocities if velocities else None,\n",
    "    }\n",
    "\n",
    "    # Create a DataFrame from the data dictionary, excluding empty lists\n",
    "    df = pd.DataFrame({k: v for k, v in data.items() if v is not None})\n",
    "    print(f\"printing columns in function...\", df.columns) # Print columns for debugging\n",
    "    \n",
    "    # Ensure proper cleanup\n",
    "    pose.close()\n",
    "    del pose\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5f7d8931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save data to specified CSV file\n",
    "def save_to_csv(df, file_path):\n",
    "    \"\"\"\n",
    "    Save the given DataFrame to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame to save.\n",
    "    file_path (str): Path to the CSV file where data will be saved.\n",
    "    \"\"\"\n",
    "    df.to_csv(file_path, index=False)  # Save DataFrame to CSV without row indices\n",
    "    print(f\"Data saved to {file_path}\")  # Print confirmation message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7a73261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "def get_video_fps(video_path):\n",
    "    \"\"\"\n",
    "    Get the frames per second (FPS) of a video.\n",
    "\n",
    "    Parameters:\n",
    "    video_path (str): Path to the video file.\n",
    "\n",
    "    Returns:\n",
    "    float: Frames per second (FPS) of the video.\n",
    "\n",
    "    Raises:\n",
    "    ValueError: If FPS could not be determined.\n",
    "    \"\"\"\n",
    "    # Open the video file using OpenCV\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Retrieve the FPS property from the video\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # Release the video capture object\n",
    "    cap.release()\n",
    "    \n",
    "    # Check if FPS is valid\n",
    "    if fps == 0:\n",
    "        raise ValueError(\"FPS could not be determined. Please check the video path or file.\")\n",
    "    \n",
    "    return fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3b095e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to track foot movements over time\n",
    "def detect_stride_cadence(landmarks, prev_left_foot, prev_right_foot, frame_time):\n",
    "    \"\"\"\n",
    "    Detect stride cadence by tracking foot movements over time.\n",
    "\n",
    "    Parameters:\n",
    "    landmarks (google._upb._message.RepeatedCompositeContainer): Pose landmarks.\n",
    "    prev_left_foot (numpy.ndarray): Previous position of the left foot.\n",
    "    prev_right_foot (numpy.ndarray): Previous position of the right foot.\n",
    "    frame_time (float): Time duration of each frame.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing boolean values indicating left and right steps, and the current positions of left and right feet.\n",
    "    \"\"\"\n",
    "    # Initialize MediaPipe Pose solution\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)\n",
    "    \n",
    "    # Extract current positions of left and right feet\n",
    "    left_foot = np.array([landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].x, landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].y])\n",
    "    right_foot = np.array([landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE].x, landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE].y])\n",
    "\n",
    "    # Detect movement by checking the change in distance\n",
    "    left_movement = np.linalg.norm(left_foot - prev_left_foot) if prev_left_foot is not None else 0\n",
    "    right_movement = np.linalg.norm(right_foot - prev_right_foot) if prev_right_foot is not None else 0\n",
    "\n",
    "    # Consider a movement significant if it's above a threshold\n",
    "    movement_threshold = 0.01  # Adjust based on camera angle & resolution\n",
    "    left_step = left_movement > movement_threshold\n",
    "    right_step = right_movement > movement_threshold\n",
    "\n",
    "    # Ensure proper cleanup\n",
    "    pose.close()\n",
    "    del pose\n",
    "    \n",
    "    return left_step, right_step, left_foot, right_foot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "345627a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_skating_metrics(df, metrics):\n",
    "    \"\"\"\n",
    "    Plot specified skating metrics over frames.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing skating metrics.\n",
    "    metrics (list): List of metrics to plot (e.g., ['Knee_Angle', 'Stride_Length']).\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(5, 5))  # Create a figure with specified size\n",
    "    num_metrics = len(metrics)  # Get the number of metrics to plot\n",
    "    \n",
    "    for i, metric in enumerate(metrics, 1):  # Loop through each metric\n",
    "        if metric not in df.columns:\n",
    "            print(f\"{metric} not in df\")\n",
    "            continue\n",
    "        plt.subplot((num_metrics + 1) // 2, 2, i)  # Create a subplot for each metric\n",
    "        plt.plot(df[\"frame\"], df[metric], marker='o')  # Plot the metric over frames\n",
    "        plt.title(f'{metric.replace(\"_\", \" \")} Over Frames')  # Set the title of the plot\n",
    "        plt.xlabel('Frame')  # Set the x-axis label\n",
    "        plt.ylabel(metric.replace(\"_\", \" \"))  # Set the y-axis label\n",
    "        plt.grid()  # Enable grid for the plot\n",
    "\n",
    "    plt.tight_layout()  # Adjust subplots to fit into the figure area\n",
    "    plt.show()  # Display the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3da816bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Functions Defined in Notebook:\n",
      "print_list_of_files_by_size\n",
      "print_memory_usage\n",
      "list_variables\n",
      "delete_variables\n",
      "printFunctions\n",
      "checkDataset\n",
      "read_APIResponseStructure\n",
      "show_memory_usage\n",
      "delete_dataframe\n",
      "optimize_dataframe\n",
      "remove_hidden_variables\n",
      "process_videos\n",
      "download_video\n",
      "get_video_properties\n",
      "extract_and_save_frames\n",
      "get_pose_landmarks\n",
      "draw_pose_landmarks\n",
      "count_frames_with_landmarks\n",
      "calculate_angle\n",
      "calculate_knee_angles\n",
      "get_landmarks\n",
      "euclidean_distance\n",
      "calculate_knee_angle\n",
      "calculate_stride_length\n",
      "calculate_hip_stability\n",
      "calculate_forward_lean\n",
      "calculate_stride_cadence\n",
      "calculate_arm_swing\n",
      "calculate_glide_length\n",
      "calculate_glide_time\n",
      "calculate_glide_ratio\n",
      "calculate_glide_symmetry\n",
      "calculate_glide_stability\n",
      "calculate_glide_efficiency\n",
      "get_position\n",
      "compute_velocity\n",
      "compute_acceleration\n",
      "calculate_metrics\n",
      "save_to_csv\n",
      "get_video_fps\n",
      "detect_stride_cadence\n",
      "plot_skating_metrics\n"
     ]
    }
   ],
   "source": [
    "printFunctions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88ed495-421c-4b3e-8775-b8fcc4332bb0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## **Section 3: Load & Save Data** <a id=\"data_load\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c4848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "url_list = [\n",
    "    \"https://www.youtube.com/watch?v=y0wIRVQDbJc\",\n",
    "]\n",
    "output_dir = \"../data\"\n",
    "frame_interval = 10\n",
    "metrics = ['knee_angle']\n",
    "csv_output_path = \"../data/skating_metrics.csv\"\n",
    "\n",
    "process_videos(url_list, output_dir, frame_interval, metrics, csv_output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca8382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "youtube_url = \"https://www.youtube.com/watch?v=y0wIRVQDbJc\"\n",
    "output_path = \"../data/temp_video_2.mp4\"\n",
    "download_video(youtube_url, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45465ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "video_length, total_frames, fps = get_video_properties(output_path)\n",
    "print(f\"Video Length: {video_length:.2f} seconds\")\n",
    "print(f\"Total Frames: {total_frames}\")\n",
    "print(f\"Frames per Second (FPS): {fps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d614af7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "video_path = \"../data/temp_video_2.mp4\"\n",
    "frame_folder_path = \"../data/frames\"\n",
    "k = 10\n",
    "extract_and_save_frames(video_path, frame_folder_path, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686affa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "frame_folder_path = \"../data/frames\"\n",
    "pose_folder_path = \"../data/pose_output\"\n",
    "\n",
    "pose_estimates = get_pose_landmarks(frame_folder_path)\n",
    "draw_pose_landmarks(pose_estimates, frame_folder_path, pose_folder_path)\n",
    "num_frames_with_landmarks = count_frames_with_landmarks(pose_estimates)\n",
    "\n",
    "print(f\"Total number of pose estimates: {num_frames_with_landmarks}\")\n",
    "print(\"Pose estimation complete! Processed frames saved in 'pose_output' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1248ced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "knee_angles = calculate_knee_angles(pose_estimates)\n",
    "for frame_name, knee_angle in knee_angles:\n",
    "    print(f\"Frame: {frame_name}, Knee Bend Angle: {knee_angle:.2f} degrees\")\n",
    "\n",
    "landmarks = get_landmarks(pose_estimates, 'left_hip', 'right_hip', 'left_knee', 'right_knee')\n",
    "for frame_landmarks in landmarks:\n",
    "    formatted_landmarks = ', '.join([f\"{key}: {value}\" for key, value in frame_landmarks.items()])\n",
    "    print(f\"Landmarks: {formatted_landmarks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e310a375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "metrics_to_plot = ['Knee_Angle', 'Stride_Length', 'Hip_Stability', 'Lean_Angle']  # List of metrics to plot\n",
    "plot_skating_metrics(df, metrics_to_plot)  # Call the function to plot the metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e235705",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m max_pages \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#load NHL interview data from API if file doesn't exist / not saved already\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(file_path):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m📂 Teams CSV file found! Loading from saved file...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m     df_interviews \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# Load NHL Interviews\n",
    "# NB --> improvements: (1) add a file_age condition, (2) add a boolean y/n refresh, (3) turn this into general function for any dataset\n",
    "\n",
    "# 📂 File path for the saved dataset (in a sibling folder)\n",
    "file_path = \"../data/all_nhl_interviews_5pages.csv\"\n",
    "\n",
    "# 🌐 URL for the NHL interviews + maximum sub-pages on main URL to scan\n",
    "main_url = \"https://mapleleafshotstove.com/leafs-news/game-day\"\n",
    "max_pages = 5\n",
    "\n",
    "#load NHL interview data from API if file doesn't exist / not saved already\n",
    "if os.path.exists(file_path):\n",
    "    print(\"📂 Teams CSV file found! Loading from saved file...\")\n",
    "    df_interviews = pd.read_csv(file_path)\n",
    "else:\n",
    "    print(\"🌍 Teams CSV file not found. Fetching data from API...\")\n",
    "    df_interviews = scrape_multiple_interviews(main_url, max_pages)\n",
    "    df_interviews.to_csv(file_path, index=False)  # Save for future use\n",
    "\n",
    "#verify\n",
    "checkDataset(df_interviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea039c1-57f0-47c8-b399-7e3bc2a5ec17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Functions Defined in Notebook:\n",
      "get_rag_answer\n",
      "get_bm25_answer\n",
      "get_bm25_top_k_answers\n",
      "print_memory_usage\n",
      "list_variables\n",
      "delete_variables\n",
      "LossLogger\n",
      "display_html_structure\n",
      "find_html_tag\n",
      "scrape_interview\n",
      "find_interview_urls\n",
      "scrape_multiple_interviews\n",
      "clean_text\n",
      "lemmatize_text\n",
      "filter_photo_questions\n",
      "filter_long_questions\n",
      "plot_question_length_distribution\n",
      "get_answer\n",
      "get_best_answer_SBERT\n",
      "calculate_exact_match_accuracy\n",
      "mean_reciprocal_rank\n",
      "mean_reciprocal_rank_SBERT\n",
      "compute_accuracy\n",
      "compute_mrr\n",
      "evaluate_bm25\n",
      "encode_text_dpr\n",
      "get_dpr_answer\n",
      "process_batches_dpr\n",
      "evaluate_dpr\n",
      "printFunctions\n",
      "checkDataset\n",
      "read_APIResponseStructure\n",
      "show_memory_usage\n",
      "delete_dataframe\n",
      "optimize_dataframe\n",
      "remove_hidden_variables\n"
     ]
    }
   ],
   "source": [
    "printFunctions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8dc504-459d-4eae-8771-be877fe1f862",
   "metadata": {},
   "source": [
    "## **Section 4: Data Preprocessing & Feature Engineering** <a id=\"data_processing\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa54b17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 832 entries, 0 to 831\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Question  832 non-null    object\n",
      " 1   Answer    832 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 13.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Keep only the necessary columns - remove URL column as its not required for training\n",
    "# remove rows with missing values\n",
    "df_cleaned = df_interviews[['Question', 'Answer']].dropna() \n",
    "\n",
    "checkDataset(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35cf98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 826 entries, 0 to 831\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Question  826 non-null    object\n",
      " 1   Answer    826 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 19.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Filter out questions that start with \"photo\" (not relevant to interview questions)\n",
    "df_cleaned = filter_photo_questions(df_cleaned)\n",
    "\n",
    "checkDataset(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb30e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the distribution of question lengths to determine the maximum length for filtering\n",
    "plot_question_length_distribution(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9a3b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 802 entries, 1 to 831\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Question  802 non-null    object\n",
      " 1   Answer    802 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 18.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Filter out questions that are much longer than others\n",
    "df_cleaned = filter_long_questions(df_cleaned, max_length=150)\n",
    "\n",
    "checkDataset(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5121cd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 802 entries, 1 to 831\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Question  802 non-null    object\n",
      " 1   Answer    802 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 18.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Create a copy of the original DataFrame before cleaning\n",
    "# This will be used for displaying the original questions and answers\n",
    "df_original = df_cleaned.copy()\n",
    "\n",
    "checkDataset(df_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74511bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Question  \\\n",
      "1     rod brindamour on craig berubes coaching style   \n",
      "2  craig berube on rod brindamours coaching succe...   \n",
      "3  steven lorentz on his memories of playing for ...   \n",
      "4  lorentz on the similarities between brindamour...   \n",
      "5  berube on the challenge presented by the hurri...   \n",
      "\n",
      "                                              Answer  \n",
      "1  he never took a shift off and thats carried ov...  \n",
      "2  he has done a great job here how he played as ...  \n",
      "3  i learned a lot it was how i broke into the le...  \n",
      "4  there are a lot actually and same with paul ma...  \n",
      "5  theyve always been a tough opponent theyve bee...  \n"
     ]
    }
   ],
   "source": [
    "# Apply cleaning to both question and answer columns\n",
    "df_cleaned['Question'] = df_cleaned['Question'].apply(clean_text)\n",
    "df_cleaned['Answer'] = df_cleaned['Answer'].apply(clean_text)\n",
    "\n",
    "# Display the first few cleaned rows\n",
    "print(df_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a9fbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Question  \\\n",
      "1        rod brindamour craig berubes coaching style   \n",
      "2  craig berube rod brindamours coaching success ...   \n",
      "3  steven lorentz memory playing brindamour carolina   \n",
      "4  lorentz similarity brindamour berubes coaching...   \n",
      "5               berube challenge presented hurricane   \n",
      "\n",
      "                                              Answer  \n",
      "1  never took shift thats carried coaching doesnt...  \n",
      "2  done great job played player brought team work...  \n",
      "3  learned lot broke league tremendous coach guy ...  \n",
      "4  lot actually paul maurice last year play hard ...  \n",
      "5  theyve always tough opponent theyve really goo...  \n"
     ]
    }
   ],
   "source": [
    "# Remove stop words (common filler words) and apply lemmatization (standardize words to their base form)\n",
    "df_cleaned['Question'] = df_cleaned['Question'].apply(lemmatize_text)\n",
    "df_cleaned['Answer'] = df_cleaned['Answer'].apply(lemmatize_text)\n",
    "\n",
    "# Display the first few cleaned rows\n",
    "print(df_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42635ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test questions: 81\n"
     ]
    }
   ],
   "source": [
    "# Split into 90% training and 10% testing\n",
    "df_train, df_test = train_test_split(df_cleaned, test_size=0.1, random_state=42)\n",
    "\n",
    "# Extract test questions and expected answers from the original DataFrame\n",
    "test_questions = df_original.loc[df_test.index, 'Question'].tolist()\n",
    "expected_answers = df_original.loc[df_test.index, 'Answer'].tolist()\n",
    "\n",
    "print(f\"Number of test questions: {len(test_questions)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6dd99a-64d3-4c97-afb8-00afd49e6609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_interviews: 0.86 MB\n",
      "df_cleaned: 0.31 MB\n",
      "df_original: 0.73 MB\n",
      "df_train: 0.25 MB\n",
      "df_test: 0.03 MB\n"
     ]
    }
   ],
   "source": [
    "show_memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d40939-d072-4814-9582-48bce2b66916",
   "metadata": {},
   "source": [
    "## **Section 5: Model 1 - Term Frequency-Inverse Document Frequency (TF-IDF)** <a id=\"logistic_model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918b909d-e1b1-4309-8046-9d97bfcc2462",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Section 5a: Train a Model (TF-IDF)** <a id=\"tfidf_train\"></a> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0c52a0-ba27-4f3a-aeb3-11b859db2f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the TfidfVectorizer to convert text data to numerical vectors\n",
    "# This is a common technique for text data in machine learning\n",
    "# It converts text data into a matrix of TF-IDF features\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit the vectorizer on the question text data (on the training set)\n",
    "# This step calculates the IDF values for each word in the corpus\n",
    "# Fit_transform learns the vocabulary and transforms the text data into vectors\n",
    "question_vectors = vectorizer.fit_transform(df_train['Question'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0c2062-6f26-4ff3-a489-ce8c8d9401a4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Section 5b: Evaluate/Test a Model (TF-IDF)** <a id=\"tfidf_eval\"></a> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e1a06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Answer: Opportunities are there. They hit some posts. They’ve missed the net a little bit. It is not clean as much at times, but overall, I am happy with the effort. They are working and doing the right things. The scoring will come.\n"
     ]
    }
   ],
   "source": [
    "# Example of predicting an answer for a question using TF-IDF vectors\n",
    "# The get_answer function uses cosine similarity to find the most similar question\n",
    "# Then returns the answer to that question\n",
    "input_question = \"How did the team perform tonight?\"\n",
    "predicted_answer = get_answer(input_question)\n",
    "print(\"Predicted Answer:\", predicted_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f29f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Predict answers for the test questions\n",
    "predicted_answers = [get_answer(q) for q in test_questions]\n",
    "\n",
    "# Calculate the accuracy of predictions using exact match (i.e., the predicted answer matches the expected answer)\n",
    "accuracy = calculate_exact_match_accuracy(expected_answers, predicted_answers)\n",
    "print(\"Model Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebfbdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reciprocal Rank (MRR): 0.010799732287647985\n"
     ]
    }
   ],
   "source": [
    "# Compute MRR -- mean reciprocal rank\n",
    "# Fuzzier evaluation by considering the rank of the correct answer in the list of predicted answers\n",
    "# Higher MRR is better\n",
    "mrr_score = mean_reciprocal_rank(test_questions, expected_answers)\n",
    "print(\"Mean Reciprocal Rank (MRR):\", mrr_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe858f51",
   "metadata": {},
   "source": [
    "**Step 5: Analyze the Results**\n",
    "- **Accuracy > 70%:** Model is doing well.\n",
    "- **Accuracy < 50%:** Model needs improvement (e.g., better cleaning, using embeddings instead of TF-IDF).\n",
    "- **MRR > 0.7:** Correct answers appear in the top-2 results.\n",
    "- **MRR < 0.4:** The model is struggling to rank answers correctly.\n",
    "\n",
    "If both Exact Match = 100% and MRR = 1.0, it means (before we split test and training data):\n",
    "- The model is retrieving perfect answers with no ranking errors.\n",
    "- It’s likely overfitting or the dataset is too easy --> **test data was in the training data (previously)!**\n",
    "- In real-world Q&A tasks, MRR is a better metric than Exact Match, since correct answers can be phrased differently.\n",
    "\n",
    "If Exact Match and MRR are below 40%, \n",
    "|Issue\t|Symptoms|\tSolution|\n",
    "|--|--|--|\n",
    "|Poor text preprocessing|\tModel treats \"win\" ≠ \"winning\" ≠ \"victory\"|\tImprove text cleaning (lemmatization, stopwords)|\n",
    "|Lack of understanding |\tModel fails for paraphrased questions |\tUse SBERT or BERT embeddings |\n",
    "| Too small dataset |\tModel retrieves random answers |\tExpand dataset with more interview questions|\n",
    "|Wrong similarity metric |\tModel ranks irrelevant answers higher\t| Tune TF-IDF parameters or switch to embeddings|\n",
    "|Over-reliance on keywords |\tModel struggles with reworded questions\t|Use word embeddings instead of TF-IDF|\n",
    "\n",
    "Update: I updated model to apply lemmatization and stop words.  Exact Match stayed at 0%.  MRR went up from 1.3 to 1.6%.  Still not significant enough.  This was with a dataset that had ~200 questions.  \n",
    "\n",
    "The model accuracy got worse with ~800 records at 1% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e93015-b8ac-4333-9c19-063f38474f10",
   "metadata": {},
   "source": [
    "### **Section 5c: Fine-Tune the Model (TF-LDF)**  <a id=\"tfldf_finetune\"></id>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413b4ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tune the TF-IDF vectorizer to improve the model performance\n",
    "# TfidfVectorizer parameters:\n",
    "# - stop_words: Remove common words\n",
    "# - ngram_range: Include word pairs (bigrams, eg \"power play\")\n",
    "# - max_df: Ignore words in 85%+ of documents (remove common words)\n",
    "# - min_df: Ignore rare words appearing in <2 docs (remove uncommon words)\n",
    "# - max_features: Limit the number of features (words) to consider\n",
    "# - sublinear_tf: Apply sublinear TF scaling (replace TF with 1 + log(TF))\n",
    "# - use_idf: Enable inverse document frequency (IDF) reweighting\n",
    "# - smooth_idf: Smooth IDF weights by adding 1 to document frequencies\n",
    "# - norm: Apply L2 normalization to feature vectors\n",
    "# - binary: Convert non-zero feature values to 1 (binary representation)\n",
    "# - token_pattern: Regular expression pattern for tokenizing words\n",
    "# - tokenizer: Custom tokenizer function (if needed, eg to keep hockey-related terms)\n",
    "# - preprocessor: Custom preprocessor function (if needed)\n",
    "# - lowercase: Convert text to lowercase\n",
    "# - encoding: Text encoding format\n",
    "# - decode_error: Error handling during text decoding\n",
    "# - strip_accents: Remove accents from characters\n",
    "# - analyzer: Custom analyzer for extracting features\n",
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words='english',  # Remove common words\n",
    "    ngram_range=(1, 2),  # Include word pairs (bigrams)\n",
    "    max_df=0.85,  # Ignore words in 85%+ of documents\n",
    "    min_df=2  # Ignore rare words appearing in <2 docs\n",
    ")\n",
    "\n",
    "question_vectors = vectorizer.fit_transform(df_train['Question'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48cb7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Predict answers for the test questions with fine-tuned vectorizer\n",
    "predicted_answers = [get_answer(q) for q in test_questions]\n",
    "\n",
    "# Calculate the accuracy of predictions using exact match (i.e., the predicted answer matches the expected answer)\n",
    "accuracy = calculate_exact_match_accuracy(expected_answers, predicted_answers)\n",
    "print(\"Model Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9733f75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reciprocal Rank (MRR): 0.011183230323748109\n"
     ]
    }
   ],
   "source": [
    "# Compute MRR -- mean reciprocal rank -- with fine-tuned vectorizer\n",
    "# Fuzzier evaluation by considering the rank of the correct answer in the list of predicted answers\n",
    "# Higher MRR is better\n",
    "mrr_score = mean_reciprocal_rank(test_questions, expected_answers)\n",
    "print(\"Mean Reciprocal Rank (MRR):\", mrr_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe366c2",
   "metadata": {},
   "source": [
    "Changing the parameters **increased MRR from 1.6% to 3.4%** with ~200 record data set.\n",
    "\n",
    "Model accuracy got worse with 800 records - 0.1%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed68b147-c3d3-417b-96dd-2fe66b8336d1",
   "metadata": {},
   "source": [
    "## **Section 6: Model 2 - Sentence BERT** <a id=\"sbert_model\"></a> ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540df088-a2e2-4444-bca6-01d148649920",
   "metadata": {},
   "source": [
    "**What is SBERT?**\n",
    "- Understands sentence meaning instead of just individual words.\n",
    "- Handles reworded questions better than TF-IDF.\n",
    "- Uses pre-trained deep learning models to generate vector representations.\n",
    "- Works well even with small datasets.\n",
    "\n",
    "\n",
    "**Why is it better than TF-IDF and BERT?**\n",
    "|Feature\t|TF-IDF|\tBERT\t|SBERT|\n",
    "|---|---|---|---|\n",
    "|Understands Word Meaning?\t|❌ No (only counts words)|\t✅ Yes (deep contextual understanding)|\t✅ Yes (optimized for sentence similarity)|\n",
    "|Handles Synonyms?\t|❌ No|\t✅ Yes|\t✅ Yes|\n",
    "|Handles Paraphrased Questions?\t|❌ No|\t✅ Yes|\t✅ Yes|\n",
    "|Computational Efficiency\t|✅ Fast|\t❌ Slow|\t✅ Fast|\n",
    "|Requires Large Training Data?\t|❌ No|\t✅ Yes (requires fine-tuning)|\t✅ Yes (but works well out-of-the-box)|\n",
    "|Handles Short Text Well?\t|✅ Yes\t|✅ Yes\t|✅ Yes|\n",
    "|Best for Q&A Retrieval?|\t❌ No|\t✅ Yes (but slow)|\t✅ Yes (faster than BERT)|\n",
    "|Best for Sentence Similarity?|\t❌ No|\t✅ Yes\t|✅ Yes (optimized for this)|\n",
    "|Pre-trained Model Available?|\t❌ No (requires manual vectorization)\t|✅ Yes\t|✅ Yes|\n",
    "|Example Use Cases|\tSearch engines, keyword matching|\tChatbots, language understanding, deep NLP tasks\t|Chatbots, Q&A, semantic search, recommendation systems|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7dabb8",
   "metadata": {},
   "source": [
    "### **Section 6a: Prepare Data for SBERT Model** <a id=\"sbert_data\"></a> ###\n",
    "\n",
    "SBERT training works with looking at the relationship between sentences.  We will prepare dataset to have:\n",
    "1. Question\n",
    "2. Correct Answer\n",
    "3. Negative Answer (a random other answer in the dataset)\n",
    "\n",
    "The SBERT model will be trained to match question closer to the correct answer then the negative answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30b7279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrive interview dataset (cleaned) and ensure all text columns are strings\n",
    "df_cleaned[\"Question\"] = df_cleaned[\"Question\"].astype(str)\n",
    "df_cleaned[\"Answer\"] = df_cleaned[\"Answer\"].astype(str)\n",
    "\n",
    "# Shuffle answers to generate negative samples\n",
    "df_cleaned[\"Negative Answer\"] = df_cleaned[\"Answer\"].sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Remove cases where positive and negative answers are the same\n",
    "df_cleaned = df_cleaned[df_cleaned[\"Answer\"] != df_cleaned[\"Negative Answer\"]]\n",
    "\n",
    "# Ensure all values are string types before passing to InputExample\n",
    "df_cleaned[\"Negative Answer\"] = df_cleaned[\"Negative Answer\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b45c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into 80% training and 20% testing for training\n",
    "df_train, df_test = train_test_split(df_cleaned, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f36aabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to InputExample format - data structure used in SBERT for training models\n",
    "train_examples = [InputExample(texts=[row[\"Question\"], row[\"Answer\"], row[\"Negative Answer\"]]) for _, row in df_train.iterrows()]\n",
    "test_examples = [InputExample(texts=[row[\"Question\"], row[\"Answer\"], row[\"Negative Answer\"]]) for _, row in df_test.iterrows()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c9bb6c",
   "metadata": {},
   "source": [
    "### **Section 6a: Use Pre-Trained SBERT Model - No Fine-Tuning** <a id=\"sbert_train\"></a> ###\n",
    "\n",
    "We will start by checking accuracy of pre-trained SBERT model without any fine-tuning using training data (i.e. domain-specific info related to NHL questions and answers).  In this case, we are just loading a model, and checking accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0cece9-41fe-433f-98ef-be505dfa9445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Check if MPS (Metal Performance Shaders) is available\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load SBERT model and move to correct device\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305bf316",
   "metadata": {},
   "source": [
    "Why all-MiniLM-L6-v2?\n",
    "- Fast & lightweight (smaller embedding size)\n",
    "- Optimized for sentence similarity\n",
    "- Good balance of accuracy vs speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd34562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.7453\n",
      "Model MRR: 0.7727\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy\n",
    "accuracy = compute_accuracy(model, df_test)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Compute MRR\n",
    "mrr_score = compute_mrr(model, df_test)\n",
    "print(f\"Model MRR: {mrr_score:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9433777-7af9-4d41-a37b-4a80be8c2bda",
   "metadata": {},
   "source": [
    "### **Section 6c: Fine-Tune SBERT with Training Data** <a id=\"sbert_hyper\"></a>\n",
    "\n",
    "This time we will fine-tune pre-trained SBERT model with NHL interview training data and check impact on accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46361a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Logger Initiated!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b33d41be704a416aa7a2bd5234106c0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='641' max='641' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [641/641 01:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.910300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define DataLoader\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=1, pin_memory=False, num_workers=0)\n",
    "\n",
    "# Define loss function: compares question vs. current answer vs. negative answer\n",
    "train_loss = losses.TripletLoss(model)\n",
    "\n",
    "# Initiate callback for logging losses during training process\n",
    "loss_logger = LossLogger(log_interval=10)\n",
    "\n",
    "# Train model with logging\n",
    "try:\n",
    "    model.fit(\n",
    "        train_objectives=[(train_dataloader, train_loss)],\n",
    "        epochs=1,\n",
    "        warmup_steps=100,\n",
    "        max_grad_norm=0.5,  # Prevents gradient explosion\n",
    "        show_progress_bar=True,\n",
    "        callback=loss_logger  # Manually pass batch callback\n",
    "    )\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(\"Error:\", e)\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0598b352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.7516\n",
      "Model MRR: 0.7481\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy\n",
    "accuracy = compute_accuracy(model, df_test)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Compute MRR\n",
    "mrr_score = compute_mrr(model, df_test)\n",
    "print(f\"Model MRR: {mrr_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76aa43e8",
   "metadata": {},
   "source": [
    "The MRR dropped from 77% to 75% after fine-tuning (i.e. the pre-trained / generic SBERT model was better!).  Why? \n",
    "\n",
    "1. **Not Enough Training Data**\n",
    "    1. SBERT is already pre-trained on a large, diverse dataset with general sentence relationships.\n",
    "    2. If your NHL dataset is too small (~800 examples), the model may overfit to the small sample, losing generalization ability.\n",
    "    3. *Fix:* \n",
    "        1. Try adding more training data (more interview Q&A pairs\n",
    "        2. Consider data augmentation (e.g., paraphrasing questions and answers using NLP).\n",
    "2. **Overfitting to Training Data**\n",
    "    1. When fine-tuning, the model may have memorized the training data instead of learning general NHL interview patterns.\n",
    "    2. This could cause it to perform well on training but poorly on test data.\n",
    "    3. *Fix:*\n",
    "        1. Use early stopping (stop training when validation loss stops improving).\n",
    "        2. Regularization techniques:\n",
    "            1. Reduce epochs (e.g., try 0.5-1 epoch instead of 2-3).\n",
    "            2. Increase dropout rate (SBERT uses dropout layers to prevent overfitting).\n",
    "3. **The Pre-Trained Model Was Already \"Good Enough\"**\n",
    "    1. SBERT is trained on diverse sentence pairs, including question-answering datasets.\n",
    "    2. Your NHL dataset may not be different enough from SBERT’s original training set, so fine-tuning doesn’t add much value and instead distorts the pre-trained weights.\n",
    "    3. *Fix:*\n",
    "        1. Instead of fine-tuning all layers, try only updating the last few layers (freeze=True for earlier layers).\n",
    "        2. Use \"adapter layers\" (lightweight layers added to SBERT without overwriting pre-trained knowledge).\n",
    "4. **Incorrect Training Setup**\n",
    "    1. You used Triplet Loss, which forces the model to distinguish between:\n",
    "        1. Question → Correct Answer (high similarity)\n",
    "        2. Question → Negative Answer (low similarity)\n",
    "    2. If your negative samples are too similar to the correct answers, the model may struggle.\n",
    "    3. Fix:\n",
    "        1. Make sure negative answers are truly incorrect (not semantically similar to correct answers).\n",
    "        2. Experiment with other loss functions:\n",
    "            1. MultipleNegativesRankingLoss (better for ranking tasks)\n",
    "            2. ContrastiveLoss (may work better for answer retrieval)\n",
    "5. Learning Rate May Be Too High\n",
    "    1. If the learning rate is too high, the model may make big jumps, forgetting useful pre-trained knowledge.\n",
    "    2. If it’s too low, the model may not learn anything meaningful.\n",
    "    3. Fix:\n",
    "        1. Try lowering the learning rate (1e-5 instead of 2e-5).\n",
    "        2. Use slower warmup steps (e.g., increase warmup_steps from 100 to 200)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82463a0",
   "metadata": {},
   "source": [
    "### **Section 6d: Optimize SBERT** <a id=\"sbert_optimize\"></a>\n",
    "\n",
    "Try to improve SBERT performance over baseline pre-trained model by:\n",
    "1. Change loss function from TripletLoss to MultipleNegativesRankingLoss --> ranks correct answers higher than negative, makes training faster\n",
    "2. Freeze earlier layers of neural net --> first layers already encode general sentence structure that the pre-trained SBERT does well.  We only wnat to fine-tune later layers with NHL-specific knowledge.\n",
    "3. Lower learning rate --> if LR is too high, model may forget pre-trained knowledge (skips too quickly)\n",
    "4. Add more training data with bigger training set OR by augmenting data (eg paraphrasing, synonyms)\n",
    "5. Try larger pre-trained SBERT model (more parameters to understand meaning of interview data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fbefd4",
   "metadata": {},
   "source": [
    "**Trial 1: Change Loss Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02fa761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-load SBERT model and move to correct device\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9651a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change loss function \n",
    "train_loss = losses.MultipleNegativesRankingLoss(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683161ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped model fit\n"
     ]
    }
   ],
   "source": [
    "run_trial = False\n",
    "# Re-train model\n",
    "try:\n",
    "    if(run_trial):\n",
    "        model.fit(\n",
    "            train_objectives=[(train_dataloader, train_loss)],\n",
    "            epochs=1,\n",
    "            warmup_steps=100,\n",
    "            max_grad_norm=0.5,  # Prevents gradient explosion\n",
    "            show_progress_bar=True,\n",
    "            callback=loss_logger  # Manually pass batch callback\n",
    "        )\n",
    "    else:  \n",
    "        print(\"Skipped model fit\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7337d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_trial = False\n",
    "\n",
    "if(run_trial):\n",
    "    # Compute accuracy\n",
    "    accuracy = compute_accuracy(model, df_test)\n",
    "    print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Compute MRR\n",
    "    mrr_score = compute_mrr(model, df_test)\n",
    "    print(f\"Model MRR: {mrr_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2adffec",
   "metadata": {},
   "source": [
    "**Trial 2: Freeze Earlier Layers**\n",
    "\n",
    "Trial 1 (loss function) + Freeze layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef062c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the first 4 layers of the model - i.e. turn off SGD\n",
    "for param in model[0].auto_model.encoder.layer[:4].parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0354bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped model fine-tuning\n"
     ]
    }
   ],
   "source": [
    "run_trial = False\n",
    "# Re-train model\n",
    "try:\n",
    "    if(run_trial):\n",
    "        model.fit(\n",
    "            train_objectives=[(train_dataloader, train_loss)],\n",
    "            epochs=1,\n",
    "            warmup_steps=100,\n",
    "            max_grad_norm=0.5,  # Prevents gradient explosion\n",
    "            show_progress_bar=True,\n",
    "            callback=loss_logger  # Manually pass batch callback\n",
    "        )\n",
    "    else:\n",
    "        print(\"Skipped model fine-tuning\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0a0b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_trial = False\n",
    "\n",
    "if(run_trial):\n",
    "    # Compute accuracy\n",
    "    accuracy = compute_accuracy(model, df_test)\n",
    "    print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Compute MRR\n",
    "    mrr_score = compute_mrr(model, df_test)\n",
    "    print(f\"Model MRR: {mrr_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699252e3",
   "metadata": {},
   "source": [
    "**Trial 3: Lower Learning Rate**\n",
    "\n",
    "Trial 1 & 2 + Lower Learning Rate (cumulative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8823b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped model fine-tuning\n"
     ]
    }
   ],
   "source": [
    "run_trial = False\n",
    "# Re-train model\n",
    "if(run_trial):\n",
    "    model.fit(\n",
    "        train_objectives=[(train_dataloader, train_loss)],\n",
    "        epochs=1,  \n",
    "        warmup_steps=200,  # Increased for smoother transition\n",
    "        max_grad_norm=0.5,  \n",
    "        optimizer_params={'lr': 1e-5},  # Lowered learning rate\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "else:\n",
    "    print(\"Skipped model fine-tuning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf15ee7b",
   "metadata": {},
   "source": [
    "**Trial 4: More Training Data**\n",
    "\n",
    "Trial 1/2/3 + more training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c0dad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-load SBERT pre-trained model\n",
    "base_model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f388f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Teams CSV file found! Loading from saved file...\n"
     ]
    }
   ],
   "source": [
    "# Get more training data from API or CSV (if saved)\n",
    "\n",
    "# 📂 File path for the saved dataset (in a sibling folder)\n",
    "file_path = \"../data/all_nhl_interviews_20pages.csv\"\n",
    "\n",
    "# 🌐 URL for the NHL interviews + maximum sub-pages on main URL to scan\n",
    "main_url = \"https://mapleleafshotstove.com/leafs-news/game-day\"\n",
    "max_pages = 20\n",
    "\n",
    "#load NHL interview data from API if file doesn't exist / not saved already\n",
    "if os.path.exists(file_path):\n",
    "    print(\"📂 Teams CSV file found! Loading from saved file...\")\n",
    "    df_interviews_lg = pd.read_csv(file_path)\n",
    "else:\n",
    "    print(\"🌍 Teams CSV file not found. Fetching data from API...\")\n",
    "    df_interviews_lg = scrape_multiple_interviews(main_url, max_pages)\n",
    "    df_interviews_lg.to_csv(file_path, index=False)  # Save for future use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db376a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2605 entries, 0 to 2604\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   URL       2605 non-null   object\n",
      " 1   Question  2597 non-null   object\n",
      " 2   Answer    2605 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 61.2+ KB\n"
     ]
    }
   ],
   "source": [
    "checkDataset(df_interviews_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84495576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pre-processing for training\n",
    "\n",
    "# Keep only the necessary columns - remove URL column as its not required for training\n",
    "# remove rows with missing values\n",
    "df_cleaned_lg = df_interviews_lg[['Question', 'Answer']].dropna() \n",
    "\n",
    "# Filter out questions that start with \"photo\" (not relevant to interview questions)\n",
    "df_cleaned_lg = filter_photo_questions(df_cleaned_lg)\n",
    "\n",
    "# Filter out questions that are much longer than others\n",
    "df_cleaned_lg = filter_long_questions(df_cleaned_lg, max_length=150)\n",
    "\n",
    "# This will be used for displaying the original questions and answers\n",
    "df_original_lg = df_cleaned_lg.copy()\n",
    "\n",
    "# Apply cleaning to both question and answer columns\n",
    "df_cleaned_lg['Question'] = df_cleaned_lg['Question'].apply(clean_text)\n",
    "df_cleaned_lg['Answer'] = df_cleaned_lg['Answer'].apply(clean_text)\n",
    "\n",
    "# Remove stop words (common filler words) and apply lemmatization (standardize words to their base form)\n",
    "df_cleaned_lg['Question'] = df_cleaned_lg['Question'].apply(lemmatize_text)\n",
    "df_cleaned_lg['Answer'] = df_cleaned_lg['Answer'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404b2613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare (Question, Correct Answer, Negative Answer) for training\n",
    "\n",
    "# Retrive interview dataset (cleaned) and ensure all text columns are strings\n",
    "df_cleaned_lg[\"Question\"] = df_cleaned_lg[\"Question\"].astype(str)\n",
    "df_cleaned_lg[\"Answer\"] = df_cleaned_lg[\"Answer\"].astype(str)\n",
    "\n",
    "# Shuffle answers to generate negative samples\n",
    "df_cleaned_lg[\"Negative Answer\"] = df_cleaned_lg[\"Answer\"].sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Remove cases where positive and negative answers are the same\n",
    "df_cleaned_lg = df_cleaned_lg[df_cleaned_lg[\"Answer\"] != df_cleaned_lg[\"Negative Answer\"]]\n",
    "\n",
    "# Ensure all values are string types before passing to InputExample\n",
    "df_cleaned_lg[\"Negative Answer\"] = df_cleaned_lg[\"Negative Answer\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b1fa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into 80% training and 20% testing for training\n",
    "df_train_lg, df_test_lg = train_test_split(df_cleaned_lg, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebca620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to InputExample format - data structure used in SBERT for training models\n",
    "train_examples_lg = [InputExample(texts=[row[\"Question\"], row[\"Answer\"], row[\"Negative Answer\"]]) for _, row in df_train_lg.iterrows()]\n",
    "test_examples_lg = [InputExample(texts=[row[\"Question\"], row[\"Answer\"], row[\"Negative Answer\"]]) for _, row in df_test_lg.iterrows()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d028c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the first 4 layers of the model - i.e. turn off SGD\n",
    "for param in base_model[0].auto_model.encoder.layer[:4].parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ecb5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Logger Initiated!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fba43bbd97e4655b26ae91cd320200c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2005' max='2005' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2005/2005 02:59, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.923100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>4.894000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>4.869100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.842300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define DataLoader\n",
    "train_dataloader_lg = DataLoader(train_examples_lg, shuffle=True, batch_size=1, pin_memory=False, num_workers=0)\n",
    "\n",
    "# Define loss function: compares question vs. current answer vs. negative answer\n",
    "train_loss = losses.TripletLoss(base_model)\n",
    "\n",
    "# Initiate callback for logging losses during training process\n",
    "loss_logger = LossLogger(log_interval=10)\n",
    "\n",
    "# Train model with logging\n",
    "try:\n",
    "    top_sbert_model = base_model.fit(\n",
    "        train_objectives=[(train_dataloader_lg, train_loss)],\n",
    "        epochs=1,\n",
    "        warmup_steps=100,\n",
    "        max_grad_norm=0.5,  # Prevents gradient explosion\n",
    "        show_progress_bar=True,\n",
    "        callback=loss_logger  # Manually pass batch callback\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346dd06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.7453 for 641 size training data\n",
      "Model MRR: 0.7727 for 641 size training data\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy\n",
    "accuracy = compute_accuracy(model, df_test)\n",
    "print(f\"Model Accuracy: {accuracy:.4f} for {df_train.shape[0]} size training data\")\n",
    "\n",
    "# Compute MRR\n",
    "mrr_score = compute_mrr(model, df_test)\n",
    "print(f\"Model MRR: {mrr_score:.4f} for {df_train.shape[0]} size training data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cb281d",
   "metadata": {},
   "source": [
    "**Trial 5: Use a larger SBERT model**\n",
    "\n",
    "\"all-mpnet-base-v2\" performs better for ranking tasks than \"all-MiniLM-L6-v2\".\n",
    "\n",
    "Took up 25GB RAM and crashed on Apple M4 / MPS CPU.  The smaller model took up 15GB RAM and was OK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a88611",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load different (larger) SBERT pre-trained model\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebc1518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped model fine-tuning\n"
     ]
    }
   ],
   "source": [
    "# loss function \n",
    "train_loss = losses.MultipleNegativesRankingLoss(model)\n",
    "\n",
    "run_trial = False\n",
    "# Re-train model\n",
    "if(run_trial):\n",
    "    model.fit(\n",
    "        train_objectives=[(train_dataloader, train_loss)],\n",
    "        epochs=1,  \n",
    "        warmup_steps=200,  # Increased for smoother transition\n",
    "        max_grad_norm=0.5,  \n",
    "        optimizer_params={'lr': 1e-5},  # Lowered learning rate\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "else:\n",
    "    print(\"Skipped model fine-tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d877d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_trial = False\n",
    "\n",
    "if(run_trial):\n",
    "    # Compute accuracy\n",
    "    accuracy = compute_accuracy(model, df_test)\n",
    "    print(f\"Model Accuracy: {accuracy:.4f} for {df_train.shape[0]} size training data\")\n",
    "\n",
    "    # Compute MRR\n",
    "    mrr_score = compute_mrr(model, df_test)\n",
    "    print(f\"Model MRR: {mrr_score:.4f} for {df_train.shape[0]} size training data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55814d7",
   "metadata": {},
   "source": [
    "**Overall - training with more data and freezing lower layers (trial 2 and 4) improved accuracy.  Larger model can't run on my machine, and LR and loss functions impact were immaterial.**\n",
    "\n",
    "**Use trial 4 model for deployment**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e684e6e7",
   "metadata": {},
   "source": [
    "## **Section 7: Model 3 - BM25**<a id=\"bm25\"></a>\n",
    "\n",
    "**BM25 (Best Matching 25)**\n",
    "- An improved TF-IDF with better term weighting and ranking for ranking relevant answers.\n",
    "- Great for retrieval tasks when you have a large dataset.\n",
    "- Implement with rank_bm25 from the rank_bm25 library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de13a532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for BM25 model\n",
    "# Splits each answer into a list of words basd on whitespace as default\n",
    "# Result is a list of list of answers, where each inner list is the words/tokens of an answer\n",
    "# Starts with large dataset (20 pages; n=2000); both training and test data because its looking at all answers to choose from\n",
    "tokenized_answers = [answer.split() for answer in df_cleaned_lg[\"Answer\"].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47347ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run BM25 model on the training data (answer tokens)\n",
    "bm25 = BM25Okapi(tokenized_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083cd58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: granato knew matthew could handle toronto market enjoy huge success nhler\n",
      "Predicted Answer: worked best possibly could worked going process didnt look team besides toronto knew door closed didnt much choice regard door soon door closed quickly looked edmonton said team place want wife got permission went visited right away knew spot key thing think grow family important hockeywise dream fit knew start would fit best would best chance win ultimately want win stanley cup opportunity play connor leon nuge dream scenario worked best possibly could\n",
      "Correct Answer: really simple coach challenge player every day guy across ice colour jersey going challenge harder coach probably need play ahl auston around nhl didnt feel player going break confidence ended struggling certain night would want go back play player tell working want player fix right essence process happens guy enter league confident enough opponent across skill level high dynamic removed night lost confidence didnt play well knew could fix talented player\n",
      "Predicted Answer Score: 558.0000\n",
      "================================================================================\n",
      "Question: keefe history heated rivalry game jet\n",
      "Predicted Answer: storied rivalry ontario theyre always exciting game intense true rivalry team playing something creates lot passion game definitely know buzz whenever theleafsand senator play going buzz town one tonight rightfully\n",
      "Correct Answer: seems like maybe stuff left canadian division played 10 time something like also two competitive highlyskilled team lot backandforth type game new coaching staff winnipeg think lot element would remain side think give u different look ability depth change look team particular depth team heading season camp something thought would different time feel could use bit boost energy little veteran presence team\n",
      "Predicted Answer Score: 1675.0000\n",
      "================================================================================\n",
      "Question: giordano reason offense drying\n",
      "Predicted Answer: holl giordano together taken much allowed sandin liljegren find game sandinliljegren really come come together u support defensemen received forward really helped everybody else better includes goaltender everybody kind covering forward slip making big play forward slipping goalie making save giving u life confidence coming together reason found success\n",
      "Correct Answer: hasnt felt sync much year sometimes oversimplify start shooting puck angle get net hopefully get ugly one way get u going five five\n",
      "Predicted Answer Score: 2382.0000\n",
      "================================================================================\n",
      "Question: matthew knies role complementing auston matthew mitch marner\n",
      "Predicted Answer: obviously wherever put mitch line done really well thats something confident comfortable mitch auston together well stack line game havent worked marner nylander together lot thats something wanted give little bit time think way matthew jarnkrok come together theyve played late give opportunity let continue develop also knowing matthew bunting really well together bunting game trending right direction look ive wanting work towards\n",
      "Correct Answer: want get puck wall earn puck back key success u right get wall get middle around net creating chaos goalscoring ability come let dance let work role around net screen goalie little thing make life little bit easier really dangerous puck goal get puck much possible make play find good area find put back net\n",
      "Predicted Answer Score: 2071.0000\n",
      "================================================================================\n",
      "Question: matthew team bounced back last year playoff disappointment best season franchise history\n",
      "Predicted Answer: greatest challenge played last week good night building theyre great team good season good team league number year good reason would expect bounce back tonight bounced back played well since played expect best term challenge great goaltending special team combine power play penalty kill among best league dangerous player dominate play lot manage hope would get another good start tonight good start day v pittsburgh good start new york try take hold game early\n",
      "Correct Answer: think thats always strive continue grow continue get better maybe extra motivation past loss stuff like think goal every year whether individually team get better push best version every day think recognize obviously team success come first thats trying build trying grow playing long time spring\n",
      "Predicted Answer Score: 627.0000\n",
      "================================================================================\n",
      "BM25 Test Accuracy: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Compute BM25 accuracy on the test set\n",
    "bm25_accuracy = evaluate_bm25(df_test_lg, bm25, df_cleaned_lg)\n",
    "print(f\"BM25 Test Accuracy: {bm25_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6726541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are the keys to the game?\n",
      "BM25 Answer: I think it is just experience. When he first came in, he was 18. He has learned a lot in the last couple of years. It hasn’t been easy for him with injuries and the way the world kind of shifted as he was entering the league. It is not easy mentally or physically going through that, but he has looked really confident so far. I think the biggest thing for him is that sometimes you try too hard and it almost works against you where you are trying, forcing, pushing, and wanting it so bad. Sometimes you just have to kind of relax out there and play your game — work hard, play smart, and don’t try to force the issue too much. I think in this camp he has done a really good job of finding his game. When you score a couple of goals, you get that confidence. That has been great to see.\n"
     ]
    }
   ],
   "source": [
    "# Test BM25\n",
    "query = \"What are the keys to the game?\"\n",
    "print(f\"Question: {query}\")\n",
    "print(\"BM25 Answer:\", get_bm25_answer(query, bm25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1e1441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are the keys to the game?\n",
      "BM25 Answer: [2604    He moves pucks well. He has played in the leag...\n",
      "863     Yeah, it was just a really awkward situation. ...\n",
      "870     With Dermott and Engvall coming back in, those...\n",
      "Name: Answer, dtype: object, 2604    He moves pucks well. He has played in the leag...\n",
      "863     Yeah, it was just a really awkward situation. ...\n",
      "870     With Dermott and Engvall coming back in, those...\n",
      "Name: Answer, dtype: object, 2604    He moves pucks well. He has played in the leag...\n",
      "863     Yeah, it was just a really awkward situation. ...\n",
      "870     With Dermott and Engvall coming back in, those...\n",
      "Name: Answer, dtype: object]\n"
     ]
    }
   ],
   "source": [
    "# Test BM25\n",
    "query = \"What are the keys to the game?\"\n",
    "top_k = 3\n",
    "print(f\"Question: {query}\")\n",
    "print(\"BM25 Answer:\", get_bm25_top_k_answers(query, bm25, top_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542505f6",
   "metadata": {},
   "source": [
    "## **Section 8: Model 4 - Dense Passage Retrieval (DPR)**<a id=\"dpr\"></a>\n",
    "\n",
    "**DPR (Dense Passage Retrieval)**\n",
    "- DPR encodes questions and answers into embeddings, using deep learning for better similarity ranking.\n",
    "- Unlike TF-IDF or BM25, DPR uses deep learning embeddings for better retrieval.\n",
    "- Pre-trained by Facebook AI on large datasets.\n",
    "- Available via Hugging Face’s transformers library.\n",
    "\n",
    "**Limitations**\n",
    "- Pre-trained model we used (single-nq-base) has 512 character limit - most answers got cut off\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ecdaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/dpr-question_encoder-single-nq-base were not used when initializing DPRQuestionEncoder: ['question_encoder.bert_model.pooler.dense.bias', 'question_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRQuestionEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRQuestionEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "# Load DPR models & tokenizers if they are not already loaded\n",
    "question_encoder = DPRQuestionEncoder.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")\n",
    "context_encoder = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "question_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")\n",
    "context_tokenizer = DPRContextEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c1efd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset of answers\n",
    "all_answers = df_cleaned_lg[\"Answer\"].tolist()\n",
    "\n",
    "# Define batch size for processing answers (to reduce memory load)\n",
    "batch_size = 4\n",
    "\n",
    "# Process answers in batches and get embeddings for each answer\n",
    "answer_embeddings = process_batches_dpr(all_answers, batch_size, context_tokenizer, context_encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a277fe4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DPR Test Accuracy: 0.0062\n"
     ]
    }
   ],
   "source": [
    "# Compute DPR accuracy on the test set\n",
    "dpr_accuracy = evaluate_dpr(df_test, question_encoder, question_tokenizer, answer_embeddings, all_answers)\n",
    "print(f\"DPR Test Accuracy: {dpr_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71629ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the key to the game?\n",
      "DPR Answer: It is always a funny game, the last one before the break. It is just the reality of it. It is one of those things where you can’t help that you have plans after the game. You have family in, or you are trying to get out. You have all sorts of stuff that is happening. Our message today was really just about focusing on the fact that you have 60 minutes remaining to play. As good as things have gone for us of late —  the two-game losing streak on the road notwithstanding — we feel good about our game and want to go into the break with that same feeling.\n"
     ]
    }
   ],
   "source": [
    "# Test DPR search retrieval\n",
    "query = \"What is the key to the game?\"\n",
    "all_answers_orig = df_original_lg[\"Answer\"]\n",
    "print(f\"Question: {query}\")\n",
    "print(\"DPR Answer:\", get_dpr_answer(query, question_tokenizer, question_encoder, answer_embeddings, all_answers_orig))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91adbf03",
   "metadata": {},
   "source": [
    "## **Section 9: Model 5 - T5 (Generative)**<a id=\"T5\"></a>\n",
    "\n",
    "**T5 (Text-to-Text Transfer Transformer)**\n",
    "- Instead of retrieving an answer, these models generate a new answer.\n",
    "- Pre-trained for question answering and summarization.\n",
    "- T5 can generate complete, human-like answers.\n",
    "- Available via Hugging Face transformers.\n",
    "\n",
    "**Limitations**\n",
    "- t5-small appears to be used for translating from EN to FR only.  Otherwise, responses have been useless\n",
    "- t5-flan appears to be able to answer more questions; still no NHL knowledge, and not robust\n",
    "\n",
    "**Use cases**\n",
    "|Task|Example Input Prompt\t|Example Output|\n",
    "|--|--|--|\n",
    "|Summarization\t|\"summarize: The hockey team played a fast-paced game and secured a win.\"|\t\"The hockey team won.\"|\n",
    "|Question Answering\t|\"question: What is the capital of Canada? answer:\"\t|\"Ottawa\"|\n",
    "|Translation\t|\"translate English to French: I play hockey.\"\t|\"Je joue au hockey.\"|\n",
    "|Text Completion\t|\"complete: The best way to win in hockey is to\"\t|\"play as a team and move the puck.\"|\n",
    "|Paraphrasing\t|\"paraphrase: Hockey is a fast-paced sport.\"|\t\"The sport of hockey is known for its speed.\"|\n",
    "|Sentiment Analysis|\t\"sentiment analysis: I love playing hockey!\"|\t\"Positive\"|\n",
    "|Grammar Correction\t|\"correct: She go to school every day.\"\t|\"She goes to school every day.\"|\n",
    "|Code Generation\t|\"write python function to add two numbers.\"\t|\"def add(a, b): return a + b\"|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1474e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23483, 16, 2379, 10, 363, 19, 8, 200, 47, 12, 2967, 21, 3, 9, 467, 58, 1]\n",
      "Quelle era la meilleure manière d'ajuster à la question : Quel est le meilleur serait pour préparer le jeu?\n"
     ]
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "# Generate an answer\n",
    "def generate_answer_t5small(question):\n",
    "    input_text = f\"Respond in French: {question}\"\n",
    "    print(tokenizer.encode(input_text))\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "    output_ids = model.generate(input_ids, max_length=50, do_sample=True)\n",
    "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Example:\n",
    "print(generate_answer_t5small(\"What is the best was to prepare for a game?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f86f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[822, 10, 363, 19, 8, 1784, 13, 2312, 58, 1525, 10, 1]\n",
      "elmerio\n"
     ]
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-small\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "\n",
    "# Generate an answer\n",
    "def generate_answer_t5flan(question):\n",
    "    input_text = f\"question: {question} answer:\"\n",
    "    print(tokenizer.encode(input_text))\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "    output_ids = model.generate(input_ids, max_length=50, do_sample=True)\n",
    "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Example:\n",
    "print(generate_answer_t5flan(\"What is the capital of USA?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fed0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21603, 10, 48, 19, 3, 9, 310, 310, 310, 310, 310, 307, 7142, 1]\n",
      "Question: this is a really really really really really long sentence, Answer: a really really really really really really really really really long sentence .\n"
     ]
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "model_t5 = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "tokenizer_t5 = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "\n",
    "# Generate an answer\n",
    "def generate_answer_t5base(question):\n",
    "    input_text = f\"summarize: {question}\"\n",
    "    print(tokenizer_t5.encode(input_text))\n",
    "    input_ids = tokenizer_t5(input_text, return_tensors=\"pt\").input_ids\n",
    "    output_ids = model_t5.generate(input_ids, max_length=50, do_sample=True)\n",
    "    return tokenizer_t5.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Example:\n",
    "question = \"this is a really really really really really long sentence\"\n",
    "generated_response = generate_answer_t5base(question)\n",
    "print(f\"Question: {question}, Answer: {generated_response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f3a82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune T5 model with NHL interview dataset\n",
    "\"\"\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./t5_finetuned\",\n",
    "    per_device_train_batch_size=8,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=df_train_lg,\n",
    "    eval_dataset=df_test_lg,\n",
    ")\n",
    "trainer.train()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e050ec6d",
   "metadata": {},
   "source": [
    "## **Section 10: Model 6 - GPT-4 (Generative)**<a id=\"gpt4\"></a>\n",
    "\n",
    "Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b841b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "openai.api_key = \"\"\n",
    "def ask_gpt(question):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": question}]\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# Test GPT-4\n",
    "query = \"What were the keys to the hockey game?\"\n",
    "print(\"GPT-4 Answer:\", ask_gpt(query))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7a43d9",
   "metadata": {},
   "source": [
    "## **Section 11: Model 7 - RAG (Hybrid)**<a id=\"rag\"></a>\n",
    "\n",
    "**RAG (Hybrid answer retrieval and generation)**\n",
    "1. Retrieve top 3 most relevant answers using BM25 or DPR.\n",
    "2. Pass retrieved answers as context to T5/GPT for final response.\n",
    "\n",
    "**Limitations**\n",
    "\n",
    "\n",
    "**Use cases**\n",
    "- tailor general purpose generative models to domain knowledge by adding specific answers to prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e649ffd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize: It is more of me trying to be the best player I possibly can day in and day out — not just on the ice but off the ice. I am in the best shape of my life right now. He and the strength guys have been on me this summer. I was here quite a bit for the summer trying to prepare for the season. I feel amazing. Sometimes, when I get sloppy or I am not at my best, he is going to let me know. That is the way a coach should be. You have to be at your best. That is the way I would put it. You have to be aware of where he is at and where everything is at on the ice. You have to give it your best. A lot of times, with him or any other great player, you need all five guys out there on the same page helping out. It is challenging, but it is fun at the same time. It is what you want to do: compete against the best in the world. Playing with him has been a big opportunity for me. We hang out off of the ice quite a bit. We build that chemistry off the ice and bring it on the ice. Playing with him is a lot of fun. I try to get open for him, dig pucks out for him, and make plays for him. Obviously, he is one of the best players in the world. Every single night, he is bringing his game. I know I have to bring mine.\n",
      "RAG Answer: Obviously, he is one of the best players in the world. Every single night,\n"
     ]
    }
   ],
   "source": [
    "# Test RAG\n",
    "query = \"Who was the best player on the ice\"\n",
    "print(\"RAG Answer:\", get_rag_answer(query, retrieval_method=\"bm25\", generator=\"t5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d9aeba-69da-4c26-8dd5-e7c08fcb44ac",
   "metadata": {},
   "source": [
    "## **Section 11: Save the Trained Model** <a id=\"save_model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4974c3a-4ec4-4842-92e7-e77b7f13d39c",
   "metadata": {},
   "source": [
    "Both **joblib** and **pickle** libraries are used to save and load Python objects (like machine learning models), but they work differently.\n",
    "\n",
    "**Using joblib (Recommended for ML models)**\n",
    "- import joblib\n",
    "- joblib.dump(best_xgb_model, \"model.pkl\")  # Save\n",
    "- model = joblib.load(\"model.pkl\")  # Load\n",
    "\n",
    "**Using pickle**\n",
    "- import pickle\n",
    "- with open(\"model.pkl\", \"wb\") as f:\n",
    "    - pickle.dump(best_xgb_model, f)\n",
    "- with open(\"model.pkl\", \"rb\") as f:\n",
    "    - model = pickle.load(f)\n",
    "\n",
    "**Summary: joblib.dump() vs. pickle.dump()**\n",
    "|Scenario|\tUse joblib?|\tUse pickle?|\n",
    "|--|--|--|\n",
    "|Saving ML models (XGBoost, Scikit-learn)?|\t✅ Yes|\t❌ No|\n",
    "|Saving general Python objects?\t|❌ No|\t✅ Yes|\n",
    "|Storing large NumPy arrays?|\t✅ Yes|\t❌ No|\n",
    "|Need speed & efficiency?\t|✅ Yes|\t❌ No|\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d35063-ace5-4c7b-887e-5615fd8f7224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle library saves the trained model \n",
    "# it serializes the model object into a binary format and writes it into a pkl file\n",
    "# later, we'll read and load the file for use in an app\n",
    "\n",
    "with open(\"xgboost_model.pkl\", \"wb\") as model_file:\n",
    "    pickle.dump(best_xgb_model, model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f8ec9c-bad2-489e-a4ef-742aefbe4b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we also need to save how the model is scaling input data so we can apply the same method in the application\n",
    "#If your app (eg Flask API) does not scale the input data the same way as during training, predictions will be off.\n",
    "\n",
    "# Check how your model was trained (re-do from Section 5c)\n",
    "scaler = StandardScaler()\n",
    "X_scaled_filtered = scaler.fit_transform(X_filtered)\n",
    "\n",
    "# Save the scaler for API use\n",
    "joblib.dump(scaler, \"scaler.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
